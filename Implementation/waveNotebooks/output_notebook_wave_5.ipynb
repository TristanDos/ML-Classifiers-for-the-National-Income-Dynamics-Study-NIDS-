{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17d6c162",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T16:51:12.604141Z",
     "iopub.status.busy": "2024-10-02T16:51:12.603815Z",
     "iopub.status.idle": "2024-10-02T16:51:12.612752Z",
     "shell.execute_reply": "2024-10-02T16:51:12.611431Z"
    },
    "papermill": {
     "duration": 0.017448,
     "end_time": "2024-10-02T16:51:12.615131",
     "exception": false,
     "start_time": "2024-10-02T16:51:12.597683",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "wave_param = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a64b4d54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T16:51:12.636500Z",
     "iopub.status.busy": "2024-10-02T16:51:12.635853Z",
     "iopub.status.idle": "2024-10-02T16:51:12.641680Z",
     "shell.execute_reply": "2024-10-02T16:51:12.640133Z"
    },
    "papermill": {
     "duration": 0.018253,
     "end_time": "2024-10-02T16:51:12.643766",
     "exception": false,
     "start_time": "2024-10-02T16:51:12.625513",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "wave_param = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec9f34a",
   "metadata": {
    "papermill": {
     "duration": 0.007404,
     "end_time": "2024-10-02T16:51:12.655576",
     "exception": false,
     "start_time": "2024-10-02T16:51:12.648172",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing\n",
    "\n",
    "Each wave must be preprocessed. This will include:\n",
    "- Assigning labels according to the CESD-10 reporting scale\n",
    "- Discretizing/classing continuous variables\n",
    "- Feature Selection/Engineering\n",
    "- Normalisation/Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11db0a40",
   "metadata": {
    "papermill": {
     "duration": 0.01296,
     "end_time": "2024-10-02T16:51:12.676744",
     "exception": false,
     "start_time": "2024-10-02T16:51:12.663784",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Preparation\n",
    "\n",
    "This includes:\n",
    "1. Collecting each wave's .csv file\n",
    "2. Renaming columns to make them more useable\n",
    "3. Type fixing (Eg. Changing Date to datetime)\n",
    "4. Incomplete data dropping (For the purpose of this Research, we only include data from participants who were 'Successfully Interviewed')\n",
    "\n",
    "**This notebook requires the user to specify which wave number to preprocess at the beginning of the file. Thus, for all 5 waves it must be run separately. Thereafter, the labeller.py file must be run to apply labels and generate labelled csv files.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbaf8636",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T16:51:12.688488Z",
     "iopub.status.busy": "2024-10-02T16:51:12.687270Z",
     "iopub.status.idle": "2024-10-02T16:51:13.783508Z",
     "shell.execute_reply": "2024-10-02T16:51:13.782425Z"
    },
    "papermill": {
     "duration": 0.655915,
     "end_time": "2024-10-02T16:51:13.337502",
     "exception": false,
     "start_time": "2024-10-02T16:51:12.681587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f9fb89917e0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/useradd/.local/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotter\n",
    "import importlib\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8749ab1a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "importlib.reload(plotter)\n",
    "\n",
    "# Parameters\n",
    "\n",
    "# wave_num = int(input(\"Enter wave to be processed: \"))\n",
    "wave_num = int(wave_param)\n",
    "\n",
    "PLOT = 0\n",
    "\n",
    "path_to_file = f\"WaveFiles/wave{wave_num}.csv\"\n",
    "\n",
    "df: pd.DataFrame = pd.read_csv(path_to_file)\n",
    "\n",
    "# Selecting column names for CESD-10 Scale related features\n",
    "cesd_col_names = [\"_a_emobth\", \"_a_emomnd\", \"_a_emodep\", \"_a_emoeff\", \"_a_emohope\",\n",
    "                \"_a_emofear\", \"_a_emoslp\", \"_a_emohap\", \"_a_emolone\", \"_a_emogo\"]\n",
    "# for i in range(len(cesd_col_names)): cesd_col_names[i] = f\"w{wave_num}\" + cesd_col_names[i]\n",
    "\n",
    "# Columns relating to non-employment based income sources. EXCLUDED: incwar_v, inco\n",
    "other_incomes = [\"incgovpen_v\", \"incppen_v\", \"incret_v\", \"incretp_v\", \"incuif_v\",\n",
    "                 \"incwc_v\", \"incdis_v\", \"incchld_v\", \"incfos_v\", \"inccare_v\",\n",
    "                 \"incint_v\", \"incinh_v\", \"incrnt_v\", \"incretr_v\",\n",
    "                 \"inclob_v\", \"incgif_v\", \"incloan_v\", \"incsale_v\"]\n",
    "for i in range(len(other_incomes)): other_incomes[i] = f\"w{wave_num}_a_\" + other_incomes[i]\n",
    "\n",
    "new_df = pd.DataFrame({})\n",
    "\n",
    "curr_year = 0\n",
    "if wave_num == 1: curr_year = '08'\n",
    "if wave_num == 2: curr_year = '10'\n",
    "if wave_num == 3: curr_year = '12'\n",
    "if wave_num == 4: curr_year = '14'\n",
    "if wave_num == 5: curr_year = '17'\n",
    "\n",
    "# Rename specific columns\n",
    "df = df.rename(columns={f'w{wave_num}_a_gen': 'gender',\n",
    "                        f'w{wave_num}_a_dob_y': 'birth_year',\n",
    "                        f'w{wave_num}_a_popgrp': 'race',\n",
    "                        f'w{wave_num}_a_marstt': 'marital_status',\n",
    "                        f'w{wave_num}_a_brnprov': 'born_province',\n",
    "\n",
    "                        f'w{wave_num}_a_mthali': 'parents_alive',\n",
    "\n",
    "                        f'w{wave_num}_a_em1': 'employed',\n",
    "                        f'w{wave_num}_a_em1pay': 'employed_take_home',\n",
    "                        f'w{wave_num}_a_em1hrs': 'employed_weekly_hours',\n",
    "                        f'w{wave_num}_a_ems': 'self_employed',\n",
    "                        f'w{wave_num}_a_emsincmn': 'self_employed_take_home',\n",
    "                        f'w{wave_num}_a_emshrs': 'self_employed_weekly_hours',\n",
    "                        f'w{wave_num}_a_emc': 'casual_work',\n",
    "                        f'w{wave_num}_a_emchrs': 'casual_weekly_hours',\n",
    "\n",
    "                        f'w{wave_num}_a_edschgrd': 'highest_grade_school',\n",
    "                        f'w{wave_num}_a_edter': 'tertiary_education',\n",
    "                        # f'w{wave_num}_a_ed07att': 'attended_courses',\n",
    "                        f'w{wave_num}_a_ed{curr_year}cur': 'currently_enrolled',\n",
    "\n",
    "                        f'w{wave_num}_a_hldes': 'health_status',\n",
    "                        f'w{wave_num}_a_hlcon': 'time_since_prev_consulation',\n",
    "                        f'w{wave_num}_a_hlconmed': 'medicine_prescribed_at_prev_consulation',\n",
    "\n",
    "                        f\"w{wave_num}_a_hl30fl\": \"flu_symptoms\",\n",
    "                        f\"w{wave_num}_a_hl30fev\": \"fever\",\n",
    "                        f\"w{wave_num}_a_hl30pc\": \"persistent_cough\",\n",
    "                        f\"w{wave_num}_a_hl30cb\": \"cough_with_blood\",\n",
    "                        f\"w{wave_num}_a_hl30tc\": \"tight_chest\",\n",
    "                        f\"w{wave_num}_a_hl30cp\": \"chest_pain\",\n",
    "                        f\"w{wave_num}_a_hl30b\": \"body_ache\",\n",
    "                        f\"w{wave_num}_a_hl30h\": \"headache\",\n",
    "                        f\"w{wave_num}_a_hl30ba\": \"back_ache\",\n",
    "                        f\"w{wave_num}_a_hl30jp\": \"joint_pain_arthritis\",\n",
    "                        f\"w{wave_num}_a_hl30v\": \"vomiting\",\n",
    "                        f\"w{wave_num}_a_hl30d\": \"diarrhoea\",\n",
    "                        f\"w{wave_num}_a_hl30w\": \"felt_weak\",\n",
    "                        f\"w{wave_num}_a_hl30pua\": \"pain_in_upper_abdomen\",\n",
    "                        f\"w{wave_num}_a_hl30pla\": \"pain_in_lower_abdomen\",\n",
    "                        f\"w{wave_num}_a_hl30pu\": \"painful_urination\",\n",
    "                        f\"w{wave_num}_a_hl30sa\": \"swelling_ankles\",\n",
    "                        f\"w{wave_num}_a_hl30r\": \"rash\",\n",
    "                        f\"w{wave_num}_a_hl30sd\": \"skin_disorders\",\n",
    "                        f\"w{wave_num}_a_hl30c\": \"conjunctivitis_eye_infection\",\n",
    "                        f\"w{wave_num}_a_hl30wl\": \"severe_weight_loss\",\n",
    "                        f\"w{wave_num}_a_hl30ye\": \"yellow_eyes\",\n",
    "                        f\"w{wave_num}_a_hl30ml\": \"memory_loss\",\n",
    "                        f\"w{wave_num}_a_hl30i\": \"serious_injury\",\n",
    "\n",
    "                        f\"w{wave_num}_a_hltb\": \"had_tubercolosis\",\n",
    "                        f\"w{wave_num}_a_hlbp\": \"had_high_blood_pressure\",\n",
    "                        f\"w{wave_num}_a_hldia\": \"had_diabetes_or_high_blood_sugar\",\n",
    "                        f\"w{wave_num}_a_hlstrk\": \"had_stroke\",\n",
    "                        f\"w{wave_num}_a_hlast\": \"had_asthma\",\n",
    "                        f\"w{wave_num}_a_hlhrt\": \"had_heart_problems\",\n",
    "                        f\"w{wave_num}_a_hlcan\": \"had_cancer\",\n",
    "                        f\"w{wave_num}_a_hltb_yr\": \"tb_diagnosis_year\",\n",
    "                        f\"w{wave_num}_a_hlbp_yr\": \"hbp_diagnosis_year\",\n",
    "                        f\"w{wave_num}_a_hldia_yr\": \"dia_diagnosis_year\",\n",
    "                        f\"w{wave_num}_a_hlstrk_yr\": \"strk_diagnosis_year\",\n",
    "                        f\"w{wave_num}_a_hlast_yr\": \"ast_diagnosis_year\",\n",
    "                        f\"w{wave_num}_a_hlhrt_yr\": \"hrt_diagnosis_year\",\n",
    "                        f\"w{wave_num}_a_hlcan_yr\": \"can_diagnosis_year\",\n",
    "\n",
    "                        f\"w{wave_num}_a_hllfexer\": \"exercise_frequency\",\n",
    "                        f\"w{wave_num}_a_hllfsmk\": \"smokes_cigarettes\",\n",
    "                        f\"w{wave_num}_a_hllfalc\": \"alcohol_frequency\",\n",
    "                        f\"w{wave_num}_a_hllfalcqnt\": \"alcohol_quantity\",\n",
    "\n",
    "                        f'w{wave_num}_a_height_1': \"height_measurement\",\n",
    "                        f'w{wave_num}_a_weight_1': \"weight_measurement\",\n",
    "                        f'w{wave_num}_a_waist_1': \"waist_measurement\",\n",
    "                        })\n",
    "\n",
    "outcome_str = f'w{wave_num}_a_outcome'\n",
    "new_data = df[df[outcome_str] == 'Successfully Interviewed']\n",
    "\n",
    "if wave_num == 2: new_data = new_data[new_data['w2_a_phase'] == 'Phase 1']\n",
    "\n",
    "df = new_data\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7febae46",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8609aacb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "PID : Integer\n",
    "\n",
    "Uniquely identifes each participant. We have to include this to ensure that when deriving new columns, we index by pid.\n",
    "So that each value in the new column is correctly associated with the partcipant\n",
    "'''\n",
    "new_df['pid'] = df['pid']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4aed880",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Section B: Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e4f62f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Temporary dataframe used to mainting indexing when deriving new columns\n",
    "temp_df = pd.DataFrame({})\n",
    "\n",
    "'''\n",
    "AGE (Derived) : Integer\n",
    "\n",
    "Provides the age of the participant at the time of the interview.\n",
    "'''\n",
    "# Calculated age by taking interview year minus year of birth\n",
    "years: pd.Series = df['birth_year'].replace('Missing', pd.NA).replace(\"Don't know\", pd.NA).replace(\"Refused\", pd.NA).dropna()\n",
    "# years = years.fillna(years.mode()[0])\n",
    "df['age'] = df[f'w{wave_num}_a_intrv_y'] - years.astype(float)\n",
    "new_df['age'] = df['age'].astype('Int32')\n",
    "\n",
    "if PLOT: plotter.plot_histogram(new_df['age'], \"Distribution of Age\")\n",
    "\n",
    "print(new_df.count())\n",
    "\n",
    "'''\n",
    "GENDER : Integer (Class)\n",
    "\n",
    "Factorizes gender.\n",
    "'''\n",
    "temp_df['gender'], getGender = pd.factorize(df['gender'])\n",
    "# print(\"GENDER:\", getGender,\"\\n\", temp_df['gender'].unique())\n",
    "\n",
    "# fig, axs = plt.subplots(1, 2, figsize=(14, 4))\n",
    "if PLOT: plotter.plot_bar(df['gender'], title=\"gender\", log_scale=False)\n",
    "\n",
    "new_df['gender'] = temp_df['gender'].fillna(temp_df['gender'].mode()[0])\n",
    "\n",
    "# # Check which rows have NaN values\n",
    "# nan_rows = new_df[new_df.isna().any(axis=1)]\n",
    "\n",
    "# # Print rows with NaN values\n",
    "# print(nan_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6750e5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "RACE : Integer (Class)\n",
    "\n",
    "Any nan or missing entries were replaced with the class \"Other\". This helps retain as much info as possible.\n",
    "'''\n",
    "# Combined Nan and Missing entries together as their own class and factorized\n",
    "df['race'] = df['race'].replace(pd.NA, 'Other').replace('Missing', 'Other')\n",
    "temp_df['race'], getRace = pd.factorize(df['race'])\n",
    "print(\"RACE:\", getRace,\"\\n\", temp_df['race'].unique())\n",
    "\n",
    "if PLOT: plotter.plot_bar(df['race'], title=\"Race before sampling\", log_scale=False)\n",
    "\n",
    "new_df['race'] = temp_df['race']\n",
    "\n",
    "'''\n",
    "MARITAL_STATUS : Integer (Class)\n",
    "\n",
    "Includes missing as an option/value.\n",
    "'''\n",
    "temp_df['marital_status'], getMaritalStatus = pd.factorize(df['marital_status'])\n",
    "print(\"MARITAL_STATUS:\", getMaritalStatus,\"\\n\", temp_df['marital_status'].unique())\n",
    "\n",
    "if PLOT: plotter.plot_bar(df['marital_status'], title=\"Marital Status\", log_scale=False, rotation=45)\n",
    "\n",
    "new_df['marital_status'] = temp_df['marital_status']\n",
    "\n",
    "'''\n",
    "BORN_PROVINCE : Integer (Class)\n",
    "\n",
    "Replaced Nan values with Missing. Importantly, about half of wave 1 seem to \n",
    "'''\n",
    "\n",
    "df['born_province'] = df['born_province'].replace(pd.NA, \"Missing\")\n",
    "# df['born_province'] = df['born_province'].dropna()\n",
    "temp_df['born_province'], getBornProvince = pd.factorize(df['born_province'])\n",
    "print(\"BORN_PROVINCE:\", getBornProvince,\"\\n\", df['born_province'].unique())\n",
    "\n",
    "if PLOT: plotter.plot_bar(df['born_province'], title=\"Born Province\", log_scale=False, rotation=90)\n",
    "\n",
    "new_df['born_province'] = temp_df['born_province']\n",
    "\n",
    "print(new_df.count())\n",
    "\n",
    "new_df = new_df.fillna(new_df.mode())\n",
    "\n",
    "print(new_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04260236",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Section C1: Children ever born (Only for Females)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c06e3e3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Section D: Parents’ education, living arrangements and vital status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9110827",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Section E: Labour market participation\n",
    "\n",
    "Also includes Section F1: Individual income from non-employment sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d487291e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "EMPLOYED : Integer (Class)\n",
    "\n",
    "1 or 0 if participant is employed at some company. Missing replaced with Refused since both indicate similar decisions\n",
    "'''\n",
    "df['employed'] = df['employed'].replace('Missing', 'Refused')\n",
    "temp_df['employed'], getEmployedBool = pd.factorize(df['employed'])\n",
    "print(\"EMPLOYED:\", getEmployedBool,\"\\n\", temp_df['employed'].unique())\n",
    "\n",
    "if PLOT: plotter.plot_bar(df['employed'], title=\"Employed by Company\", log_scale=False, rotation=0)\n",
    "\n",
    "new_df['employed'] = temp_df['employed']\n",
    "\n",
    "'''\n",
    "EMPLOYED_TAKE_HOME : FLOAT -> Integer (Class)\n",
    "\n",
    "Replaced any item that was a string or NA with 0. The amounts are discretized into bins.\n",
    "'''\n",
    "df['employed_take_home'] = df['employed_take_home'].replace('Missing', 0.0).replace(\"Refused\", 0.0).replace(\"Don't know\", 0.0).replace(pd.NA, 0.0).replace(\"Not Applicable\", 0.0)\n",
    "\n",
    "temp_df['employed_take_home'], getEmployedTakeHome = pd.factorize(pd.cut(pd.to_numeric(df['employed_take_home']), bins=30))\n",
    "\n",
    "if PLOT: plotter.plot_histogram(temp_df['employed_take_home'], title=\"Employed Monthly Earnings\", log_scale=True, rotation=90)\n",
    "\n",
    "new_df['employed_take_home'] = temp_df['employed_take_home']\n",
    "\n",
    "'''\n",
    "EMPLOYED_WEEKLY_HOURS : Integer\n",
    "\n",
    "Replaced any item that was a string or NA with 0. I haven't binned this feature since Hours worked weekly will have frequent hour amounts.\n",
    "'''\n",
    "df['employed_weekly_hours'] = df['employed_weekly_hours'].replace('Missing', 0).replace(\"Refused\", 0).replace(\"Don't know\", 0).replace(pd.NA, 0).replace(\"Not Applicable\", 0)\n",
    "df['employed_weekly_hours'] =  pd.to_numeric(df['employed_weekly_hours']).astype('Int32')\n",
    "\n",
    "# CAPPED ENTRIES WHERE EMPLOYED WEEKLY HOURS IS GREATER THAN 100\n",
    "# IF A PARTICIPANT HAS MORE THAN 100 HOURS WORKED, THIS GETS CLIPPED DOWN TO 100\n",
    "temp_df['employed_weekly_hours'] = df['employed_weekly_hours'].clip(upper=100)\n",
    "\n",
    "if PLOT: plotter.plot_histogram(temp_df['employed_weekly_hours'], title=\"Employed Weekly Hours Worked\", log_scale=False, rotation=0)\n",
    "\n",
    "new_df['employed_weekly_hours'] = temp_df['employed_weekly_hours'] \n",
    "\n",
    "\n",
    "'''\n",
    "SELF_EMPLOYED : Integer (Class)\n",
    "\n",
    "1 or 0 if participant is self employed. Missing replaced with Refused since both indicate similar decisions\n",
    "'''\n",
    "df['self_employed'] = df['self_employed'].replace('Missing', 'Refused')\n",
    "temp_df['self_employed'], getSelfEmployedBool = pd.factorize(df['self_employed'])\n",
    "print(\"SELF_EMPLOYED:\", getSelfEmployedBool,\"\\n\", temp_df['self_employed'].unique())\n",
    "\n",
    "if PLOT: plotter.plot_bar(df['self_employed'], title=\"Self Employed\", log_scale=False, rotation=0)\n",
    "\n",
    "new_df['self_employed'] = temp_df['self_employed']\n",
    "\n",
    "'''\n",
    "SELF_EMPLOYED_TAKE_HOME : FLOAT -> Integer (Class)\n",
    "\n",
    "Replaced any item that was a string or NA with 0. The amounts are discretized into bins.\n",
    "'''\n",
    "df['self_employed_take_home'] = df['self_employed_take_home'].replace('Missing', 0.0).replace(\"Refused\", 0.0).replace(\"Don't know\", 0.0).replace(pd.NA, 0.0).replace(\"Not Applicable\", 0.0)\n",
    "\n",
    "temp_df['self_employed_take_home'], getSelfEmployedTakeHome = pd.factorize(pd.cut(pd.to_numeric(df['self_employed_take_home']), bins=30))\n",
    "\n",
    "if PLOT: plotter.plot_histogram(df['self_employed_take_home'], title=\"Self Employed Monthly Earnings\", log_scale=True, rotation=90)\n",
    "\n",
    "new_df['self_employed_take_home'] = temp_df['self_employed_take_home']\n",
    "\n",
    "'''\n",
    "EMPLOYED_WEEKLY_HOURS : Integer\n",
    "\n",
    "Replaced any item that was a string or NA with 0. I haven't binned this feature since Hours worked weekly will have frequent hour amounts.\n",
    "'''\n",
    "df['self_employed_weekly_hours'] = df['self_employed_weekly_hours'].replace('Missing', 0).replace(\"Refused\", 0).replace(\"Don't know\", 0).replace(pd.NA, 0).replace(\"Not Applicable\", 0)\n",
    "df['self_employed_weekly_hours'] =  pd.to_numeric(df['self_employed_weekly_hours']).astype('Int32')\n",
    "\n",
    "# CAPPED ENTRIES WHERE EMPLOYED WEEKLY HOURS IS GREATER THAN 100\n",
    "# IF A PARTICIPANT HAS MORE THAN 100 HOURS WORKED, THIS GETS CLIPPED DOWN TO 100\n",
    "temp_df['self_employed_weekly_hours'] = df['self_employed_weekly_hours'].clip(upper=100)\n",
    "\n",
    "if PLOT: plotter.plot_histogram(temp_df['self_employed_weekly_hours'], title=\"Self Employed Weekly Hours Worked\", log_scale=False, rotation=0)\n",
    "\n",
    "new_df['self_employed_weekly_hours'] = temp_df['self_employed_weekly_hours'] \n",
    "\n",
    "'''\n",
    "CASUAL_WORK : Integer (Class)\n",
    "\n",
    "1 or 0 if participant is does casual work, eg. Farming, Vendoring. Missing replaced with Refused since both indicate similar decisions\n",
    "'''\n",
    "df['casual_work'] = df['casual_work'].replace('Missing', 'Refused')\n",
    "temp_df['casual_work'], getCasualWorkBool = pd.factorize(df['casual_work'])\n",
    "print(\"CASUAL_WORK:\", getCasualWorkBool,\"\\n\", temp_df['casual_work'].unique())\n",
    "\n",
    "if PLOT: plotter.plot_bar(df['casual_work'], title=\"Casual Work\", log_scale=False, rotation=0)\n",
    "\n",
    "new_df['casual_work'] = temp_df['casual_work']\n",
    "\n",
    "'''\n",
    "CASUAL_WEEKLY_HOURS : Integer\n",
    "\n",
    "Replaced any item that was a string or NA with 0. I haven't binned this feature since Hours worked weekly will have frequent hour amounts.\n",
    "'''\n",
    "df['casual_weekly_hours'] = df['casual_weekly_hours'].replace('Missing', 0).replace(\"Refused\", 0).replace(\"Don't know\", 0).replace(pd.NA, 0).replace(\"Not Applicable\", 0)\n",
    "df['casual_weekly_hours'] =  pd.to_numeric(df['casual_weekly_hours']).astype('Int32')\n",
    "\n",
    "# CAPPED ENTRIES WHERE EMPLOYED WEEKLY HOURS IS GREATER THAN 100\n",
    "# IF A PARTICIPANT HAS MORE THAN 100 HOURS WORKED, THIS GETS CLIPPED DOWN TO 100\n",
    "temp_df['casual_weekly_hours'] = df['casual_weekly_hours'].clip(upper=100)\n",
    "\n",
    "if PLOT: plotter.plot_histogram(temp_df['casual_weekly_hours'], title=\"Weekly Hours Worked for Casual Work\", log_scale=False, rotation=0)\n",
    "\n",
    "new_df['casual_weekly_hours'] = temp_df['casual_weekly_hours'] \n",
    "\n",
    "'''\n",
    "EXTRA_INCOME (Derived) : Float\n",
    "\n",
    "There are a list of columns relating to extra incomes received from various sources. These include government grants, gifts, dontations etc.\n",
    "\n",
    "Each column will be summed to form a new column that represents the total income gained from extra sources, other than employment.\n",
    "'''\n",
    "# # Firstly replacing entries which aren't numbers with 0\n",
    "# for income_type in other_incomes:\n",
    "#     df[income_type] = df[income_type].replace('Missing', 0.0).replace(\"Refused\", 0.0).replace(\"Don't know\", 0.0).replace(pd.NA, 0.0).replace(\"Not Applicable\", 0.0)\n",
    "#     df[income_type] = pd.to_numeric(df[income_type])\n",
    "#     print(df[income_type].unique())\n",
    "\n",
    "# temp_df['extra_income'] = df[other_incomes[0]]\n",
    "# for i in range(1, len(other_incomes)):\n",
    "#     temp_df['extra_income'] += df[other_incomes[i]]\n",
    "\n",
    "# if PLOT: plotter.plot_histogram(temp_df['extra_income'], title=\"Extra income gained from sources other than employment\", log_scale=True, rotation=90)\n",
    "\n",
    "# new_df['extra_income'] = pd.factorize(pd.cut(pd.to_numeric(temp_df['extra_income']), bins=30))\n",
    "\n",
    "# print(temp_df['extra_income'].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6661632",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Section G: Personal ownership and debt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b407a4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Section H: Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6695ce",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "HIGHEST_GRADE_SCHOOL : Integer (Class)\n",
    "\n",
    "Includes missing, refused, not applicable and don't know as options/values.\n",
    "'''\n",
    "temp_df['highest_grade_school'], getHighestGradeSchool = pd.factorize(df['highest_grade_school'])\n",
    "print(\"HIGHEST_GRADE_SCHOOL:\", getHighestGradeSchool,\"\\n\", temp_df['highest_grade_school'].unique())\n",
    "\n",
    "if PLOT: plotter.plot_bar(df['highest_grade_school'], title=\"Highest grade completed of Schooling\", log_scale=False, rotation=90)\n",
    "\n",
    "new_df['highest_grade_school'] = temp_df['highest_grade_school']\n",
    "\n",
    "'''\n",
    "TERTIARY_EDUCATION : Integer (Class)\n",
    "\n",
    "Whether the participant completed some form of Tertiary Education (Degrees, Certificates etc.)\n",
    "\n",
    "Includes missing, refused, and don't know as options/values.\n",
    "'''\n",
    "temp_df['tertiary_education'], getTertiaryEducation = pd.factorize(df['tertiary_education'].replace(pd.NA, 'Missing'))\n",
    "print(\"TERTIARY_EDUCATION:\", getTertiaryEducation,\"\\n\", temp_df['tertiary_education'].unique())\n",
    "\n",
    "if PLOT: plotter.plot_bar(df['tertiary_education'], title=\"Attended Tertiary Schooling (Degrees, Certificates etc.)\", log_scale=False, rotation=0)\n",
    "\n",
    "new_df['tertiary_education'] = temp_df['tertiary_education']\n",
    "\n",
    "'''\n",
    "CURRENTLY_ENROLLED : Integer (Class)\n",
    "\n",
    "Whether the participant is enrolled in some form of Schooling or Education this year.\n",
    "\n",
    "Includes missing as an option/value.\n",
    "'''\n",
    "temp_df['currently_enrolled'], getCurrentlyEnrolled = pd.factorize(df['currently_enrolled'].replace(pd.NA, 'Missing'))\n",
    "print(\"CURRENTLY_ENROLLED:\", getCurrentlyEnrolled,\"\\n\", temp_df['currently_enrolled'].unique())\n",
    "\n",
    "if PLOT: plotter.plot_bar(df['currently_enrolled'], title=\"Currently Enrolled\", log_scale=False, rotation=0)\n",
    "\n",
    "new_df['currently_enrolled'] = temp_df['currently_enrolled']\n",
    "\n",
    "# '''\n",
    "# ATTENDED_COURSES : Integer (Class)\n",
    "\n",
    "# Whether the participant attended university/school courses in the prior year.\n",
    "\n",
    "# Includes missing, refused, and don't know as options/values.\n",
    "# '''\n",
    "# temp_df['attended_courses'], getAttendedCourses = pd.factorize(df['attended_courses'].replace(pd.NA, 'Missing'))\n",
    "# print(\"ATTENDED_COURSES:\", getAttendedCourses,\"\\n\", temp_df['attended_courses'].unique())\n",
    "\n",
    "# if PLOT: plotter.plot_bar(df['attended_courses'], title=\"Attended Courses Last Year (Degrees, Certificates etc.)\", log_scale=False, rotation=0)\n",
    "\n",
    "# new_df['attended_courses'] = temp_df['attended_courses']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb39bce",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Section J: Health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abcbc95",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "HEALTH_STATUS : Integer (Class)\n",
    "\n",
    "Ranges from 1-5. Self-description of current health, 1 being excellent, 5 being poor\n",
    "\n",
    "Decided to include missing, don't know and refused as options since they might reveal correlations.\n",
    "'''\n",
    "temp_df['health_status'], getHealthStatus = pd.factorize(df['health_status'])\n",
    "print(\"HEALTH_STATUS:\", getHealthStatus,\"\\n\", temp_df['health_status'].unique())\n",
    "\n",
    "if PLOT: plotter.plot_bar(df['health_status'], title=\"Health status\", log_scale=False, rotation=30)\n",
    "\n",
    "'''\n",
    "The following section is a list of health condition features. The participant was asked to say yes to any of the following conditions if they experienced them in the past 30 days.\n",
    "'''\n",
    "\n",
    "conditions = [\n",
    "    \"flu_symptoms\",\n",
    "    \"fever\",\n",
    "    \"persistent_cough\",\n",
    "    \"cough_with_blood\",\n",
    "    \"tight_chest\",\n",
    "    \"chest_pain\",\n",
    "    \"body_ache\",\n",
    "    \"headache\",\n",
    "    \"back_ache\",\n",
    "    \"joint_pain_arthritis\",\n",
    "    \"vomiting\",\n",
    "    \"diarrhoea\",\n",
    "    \"felt_weak\",\n",
    "    \"pain_in_upper_abdomen\",\n",
    "    \"pain_in_lower_abdomen\",\n",
    "    \"painful_urination\",\n",
    "    \"swelling_ankles\",\n",
    "    \"rash\",\n",
    "    \"skin_disorders\",\n",
    "    \"conjunctivitis_eye_infection\",\n",
    "    \"severe_weight_loss\",\n",
    "    \"yellow_eyes\",\n",
    "    \"memory_loss\",\n",
    "    \"serious_injury\"\n",
    "]\n",
    "\n",
    "getConditions = []\n",
    "\n",
    "for condition in conditions:\n",
    "    new_df[condition], getCondition = pd.factorize(df[condition].replace('Not Applicable', 'Missing'))\n",
    "    getConditions.append(getCondition)\n",
    "\n",
    "# Generate summary statistics for all condition columns\n",
    "summary_stats = new_df[conditions].describe()\n",
    "\n",
    "# Print the summary stats\n",
    "print(\"SUMMARY STATISTICS FOR VARIOUS HEALTH CONDITIONS\\n\", summary_stats)\n",
    "\n",
    "'''\n",
    "TIME_SINCE_PREV_CONSULTATION : Integer (Class)\n",
    "\n",
    "Options range from 1 (In the last 30 days) to 8 (Never)\n",
    "'''\n",
    "if wave_num == 2: df['time_since_prev_consulation'] = df['time_since_prev_consulation'].replace(\"Not asked in Phase 2\", \"Don't know\")\n",
    "\n",
    "temp_df['time_since_prev_consulation'], getTimeSincePrevConsulation = pd.factorize(df['time_since_prev_consulation'].replace(\"Not asked in Phase 2\", \"Don't know\"))\n",
    "print(\"TIME_SINCE_PREV_CONSULTATION:\", getTimeSincePrevConsulation,\"\\n\", temp_df['time_since_prev_consulation'].unique())\n",
    "\n",
    "if PLOT: plotter.plot_bar(df['time_since_prev_consulation'], title=\"Last health consultation\", log_scale=False, rotation=90)\n",
    "\n",
    "new_df['time_since_prev_consulation'] = temp_df['time_since_prev_consulation']\n",
    "\n",
    "'''\n",
    "MEDICINE_PRESCRIBED_AT_PREV_CONSULTATION: Integer (Class)\n",
    "\n",
    "If this feature is Nan, it indicates that the participants previous consultation was more than one and less two years ago, according to the questionnaire.\n",
    "Thus I created a new value \"Consultation Too Distant\" for these entries.\n",
    "'''\n",
    "df['medicine_prescribed_at_prev_consulation'] = df['medicine_prescribed_at_prev_consulation'].replace(pd.NA, \"Consultation Too Distant\")\n",
    "temp_df['medicine_prescribed_at_prev_consulation'], getMedicinePrescribedAtPrevConsulation = pd.factorize(df['medicine_prescribed_at_prev_consulation'])\n",
    "print(\"MEDICINE_PRESCRIBED_AT_PREV_CONSULTATION:\", getMedicinePrescribedAtPrevConsulation,\"\\n\", temp_df['medicine_prescribed_at_prev_consulation'].unique())\n",
    "\n",
    "if PLOT: plotter.plot_bar(df['medicine_prescribed_at_prev_consulation'], title=\"Medicine prescribed at last health consultation\", log_scale=False, rotation=70)\n",
    "\n",
    "new_df['medicine_prescribed_at_prev_consulation'] = temp_df['medicine_prescribed_at_prev_consulation']\n",
    "\n",
    "\n",
    "'''\n",
    "The following section is a list of persistent/long-term health conditions.\n",
    "\n",
    "Each condition is a separate feature, with an associated feature for the number of years since the diagnosis (at the time of the interview).\n",
    "'''\n",
    "\n",
    "temp_df['had_tubercolosis'], getHadTB = pd.factorize(df['had_tubercolosis'].replace({'No': 0, \"Yes\": 1}))\n",
    "temp_df['had_high_blood_pressure'], getHadTB = pd.factorize(df['had_high_blood_pressure'].replace({'No': 0, \"Yes\": 1}))\n",
    "temp_df['had_diabetes_or_high_blood_sugar'], getHadTB = pd.factorize(df['had_diabetes_or_high_blood_sugar'].replace({'No': 0, \"Yes\": 1}))\n",
    "temp_df['had_stroke'], getHadTB = pd.factorize(df['had_stroke'].replace({'No': 0, \"Yes\": 1}))\n",
    "temp_df['had_asthma'], getHadTB = pd.factorize(df['had_asthma'].replace({'No': 0, \"Yes\": 1}))\n",
    "temp_df['had_heart_problems'], getHadTB = pd.factorize(df['had_heart_problems'].replace({'No': 0, \"Yes\": 1}))\n",
    "temp_df['had_cancer'], getHadTB = pd.factorize(df['had_cancer'].replace({'No': 0, \"Yes\": 1}))\n",
    "\n",
    "persistent_conditions = ['tb', 'hbp', 'dia', 'strk', 'ast', 'hrt', 'can']\n",
    "mapping = {'tb': 'tubercolosis', 'hbp': 'high_blood_pressure', 'dia': 'diabetes_or_high_blood_sugar', 'strk': 'stroke', 'ast': 'asthma', 'hrt': 'heart_problems', 'can': 'cancer'}\n",
    "\n",
    "for con in persistent_conditions:\n",
    "    # Replace invalid entries in tb_diagnosis_year with -200 as a flag\n",
    "    years = df[f'{con}_diagnosis_year'].replace(['Missing', \"Don't know\", 'Refused', pd.NA], -200).dropna().astype(float)\n",
    "\n",
    "    # Calculate diagnosis age for those who had tuberculosis\n",
    "    temp_df[f'{con}_diagnosis_age'] = df[f'w{wave_num}_a_intrv_y'] - years\n",
    "\n",
    "    # Identify entries where the above flag is true\n",
    "    temp_df[f'w{wave_num}_a_intrv_y'] = df[f'w{wave_num}_a_intrv_y']\n",
    "    condition = (temp_df[f'{con}_diagnosis_age'] == temp_df[f'w{wave_num}_a_intrv_y'] + 200)\n",
    "\n",
    "    # Set those diagnosis age entries to -1\n",
    "    temp_df.loc[condition, f'{con}_diagnosis_age'] = -1\n",
    "\n",
    "    mapped_condition = mapping[con]\n",
    "    # Set diagnosis age to -1 if 'had_tuberculosis' is not 1\n",
    "    temp_df[f'{con}_diagnosis_age'] = temp_df[f'{con}_diagnosis_age'].where(df[f'had_{mapped_condition}'] != 1, -1)\n",
    "\n",
    "    # Convert to Int32 (to allow for -1 and NaN values)\n",
    "    new_df[f'{con}_diagnosis_age'] = temp_df[f'{con}_diagnosis_age'].astype('Int32')\n",
    "\n",
    "    print(new_df[f'{con}_diagnosis_age'].unique(), new_df[f'{con}_diagnosis_age'].count())\n",
    "\n",
    "'''\n",
    "EXERCISE_FREQUENCY : Integer (Class)\n",
    "\n",
    "Options are:\n",
    "Never\n",
    "Less than once a week\n",
    "Once a week\n",
    "Twice a week\n",
    "Three or more times a week\n",
    "'''\n",
    "if wave_num == 2: df['exercise_frequency'] = df['exercise_frequency'].replace(\"Not asked in Phase 2\", \"Don't know\")\n",
    "\n",
    "temp_df['exercise_frequency'], getExerciseFrequency = pd.factorize(df['exercise_frequency'].replace(\"Not asked in Phase 2\", \"Don't know\"))\n",
    "print(\"EXERCISE_FREQUENCY:\", getExerciseFrequency,\"\\n\", temp_df['exercise_frequency'].unique())\n",
    "\n",
    "if PLOT: plotter.plot_bar(df['exercise_frequency'], title=\"Frequency of Exercise\", log_scale=False, rotation=70)\n",
    "\n",
    "new_df['exercise_frequency'] = temp_df['exercise_frequency']\n",
    "\n",
    "'''\n",
    "SMOKES_CIGARETTES : Integer (Class)\n",
    "\n",
    "Yes or no.\n",
    "'''\n",
    "if wave_num == 2: df['smokes_cigarettes'] = df['smokes_cigarettes'].replace(\"Not asked in Phase 2\", \"Don't know\")\n",
    "\n",
    "df['smokes_cigarettes'] = df['smokes_cigarettes'].replace({pd.NA: 'Missing', 'Not Applicable': 'Missing'}).replace(\"Not asked in Phase 2\", \"Don't know\")\n",
    "temp_df['smokes_cigarettes'], getSmoker = pd.factorize(df['smokes_cigarettes'])\n",
    "print(\"SMOKES_CIGARETTES:\", getSmoker,\"\\n\", temp_df['smokes_cigarettes'].unique())\n",
    "\n",
    "if PLOT: plotter.plot_bar(df['smokes_cigarettes'], title=\"Whether participant smokes\", log_scale=False, rotation=0)\n",
    "\n",
    "new_df['smokes_cigarettes'] = temp_df['smokes_cigarettes']\n",
    "\n",
    "'''\n",
    "ALCOHOL_FREQUENCY : Integer (Class)\n",
    "\n",
    "Options are:\n",
    "I have never drunk alcohol→ SKIP TO J33 1\n",
    "I no longer drink alcohol→ SKIP TO J33 2\n",
    "I drink very rarely 3\n",
    "Less than once a week 4\n",
    "On 1 or 2 days a week 5\n",
    "On 3 or 4 days a week 6\n",
    "On 5 or 6 days a week 7\n",
    "Every day 8\n",
    "'''\n",
    "if wave_num == 2: df['alcohol_frequency'] = df['alcohol_frequency'].replace(\"Not asked in Phase 2\", \"Don't know\")\n",
    "\n",
    "temp_df['alcohol_frequency'], getAlcoholFrequency = pd.factorize(df['alcohol_frequency'].replace(\"Not asked in Phase 2\", \"Don't know\"))\n",
    "print(\"ALCOHOL_FREQUENCY:\", getAlcoholFrequency,\"\\n\", temp_df['alcohol_frequency'].unique())\n",
    "\n",
    "if PLOT: plotter.plot_bar(df['alcohol_frequency'], title=\"Frequency of alcohol drinking\", log_scale=False, rotation=70)\n",
    "\n",
    "new_df['alcohol_frequency'] = temp_df['alcohol_frequency']\n",
    "\n",
    "'''\n",
    "ALCOHOL_QUANTITY : Integer (Class)\n",
    "\n",
    "Options are:\n",
    "13 or more standard drinks 1\n",
    "9 to 12 standard drinks 2\n",
    "7 to 8 standard drinks 3\n",
    "5 to 6 standard drinks 4\n",
    "3 or 4 standard drinks 5\n",
    "1 or 2 standard drinks 6\n",
    "'''\n",
    "if wave_num == 2: df['alcohol_quantity'] = df['alcohol_quantity'].replace(\"Not asked in Phase 2\", \"Don't know\")\n",
    "\n",
    "temp_df['alcohol_quantity'], getAlcoholQuantity = pd.factorize(df['alcohol_quantity'])\n",
    "print(\"ALCOHOL_QUANTITY:\", getAlcoholQuantity,\"\\n\", temp_df['alcohol_quantity'].unique())\n",
    "\n",
    "if PLOT: plotter.plot_bar(df['alcohol_quantity'], title=\"Quantity of alcohol drinking\", log_scale=False, rotation=70)\n",
    "\n",
    "new_df['alcohol_quantity'] = temp_df['alcohol_quantity']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5880c4f3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Section N: Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b090865",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# f'w{wave_num}_a_height_1'\n",
    "# f'w{wave_num}_a_weight_1'\n",
    "# f'w{wave_num}_a_waist_1'\n",
    "\n",
    "'''\n",
    "The following columns all relate to measurements done during the interview of each participant.\n",
    "\n",
    "These include: Height, Weight, Waist\n",
    "\n",
    "Each column is cut/binned to create new discrete columns.\n",
    "'''\n",
    "\n",
    "# Replace NaN values with the mean of the column\n",
    "\n",
    "# print(df['height_measurement'].replace({'Missing': pd.NA, 'Refused': pd.NA, 'Not Applicable': pd.NA, \"Don't know\": pd.NA}).dropna().count())\n",
    "# height_ave = df['height_measurement'].replace({'Missing': pd.NA, 'Refused': pd.NA, 'Not Applicable': pd.NA, \"Don't know\": pd.NA}).dropna().astype(float).mean()\n",
    "# weight_ave = df['weight_measurement'].replace({'Missing': pd.NA, 'Refused': pd.NA, 'Not Applicable': pd.NA, \"Don't know\": pd.NA}).dropna().astype(float).mean()\n",
    "# waist_ave = df['waist_measurement'].replace({'Missing': pd.NA, 'Refused': pd.NA, 'Not Applicable': pd.NA, \"Don't know\": pd.NA}).dropna().astype(float).mean()\n",
    "\n",
    "if wave_num == 2:\n",
    "    df['height_measurement'] = df['height_measurement'].replace('Not asked in Phase 2', pd.NA)\n",
    "    df['weight_measurement'] = df['weight_measurement'].replace('Not asked in Phase 2', pd.NA)\n",
    "    df['waist_measurement'] = df['waist_measurement'].replace('Not asked in Phase 2', pd.NA)\n",
    "\n",
    "height_diff = df['height_measurement'].count()\n",
    "weight_diff = df['weight_measurement'].count()\n",
    "waist_diff = df['waist_measurement'].count()\n",
    "\n",
    "temp_df['height_measurement'] = df['height_measurement'].replace({'Missing': pd.NA, 'Refused': pd.NA, 'Not Applicable': pd.NA, \"Don't know\": pd.NA}).dropna().astype(float)\n",
    "temp_df['weight_measurement'] = df['weight_measurement'].replace({'Missing': pd.NA, 'Refused': pd.NA, 'Not Applicable': pd.NA, \"Don't know\": pd.NA}).dropna().astype(float)\n",
    "temp_df['waist_measurement'] = df['waist_measurement'].replace({'Missing': pd.NA, 'Refused': pd.NA, 'Not Applicable': pd.NA, \"Don't know\": pd.NA}).dropna().astype(float)\n",
    "\n",
    "if PLOT: plotter.plot_histogram(temp_df['height_measurement'], \"Distribution of Heights\")\n",
    "if PLOT: plotter.plot_histogram(temp_df['weight_measurement'], \"Distribution of Weights\")\n",
    "if PLOT: plotter.plot_histogram(temp_df['waist_measurement'], \"Distribution of Waist Measurements\")\n",
    "\n",
    "new_df['height_measurement'] = pd.cut(temp_df['height_measurement'], bins=100).astype('category').cat.codes\n",
    "new_df['weight_measurement'] = pd.cut(temp_df['weight_measurement'], bins=100).astype('category').cat.codes\n",
    "new_df['waist_measurement'] = pd.cut(temp_df['waist_measurement'], bins=100).astype('category').cat.codes\n",
    "\n",
    "height_diff -= new_df['height_measurement'].count()\n",
    "weight_diff -= new_df['weight_measurement'].count()\n",
    "waist_diff -=  new_df['waist_measurement'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b91095",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fb1e6a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Sampling for dropped values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f5b45e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Count before dropping NA:\\n\", df['pid'].count())\n",
    "\n",
    "new_df = new_df.dropna()\n",
    "\n",
    "print(\"Count after dropping NA:\\n\", new_df['pid'].count())\n",
    "\n",
    "diff = df['pid'].count() - new_df['pid'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ff5dfb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Exporting Dataframes to CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afa47c6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col in cesd_col_names:    \n",
    "    # Header text for each column based on wave\n",
    "    header = 'w' + str(wave_num)\n",
    "\n",
    "    new_df[header+col] = df[header+col]\n",
    "\n",
    "new_df.to_csv(f'CSV/wave{wave_num}_select.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3aaeb7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Labelling\n",
    "\n",
    "Each participant was **labelled according to the CESD-10 reporting scale**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f641bb3c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from tqdm import tqdm\n",
    "# from typing import List\n",
    "# importlib.reload(plotter)\n",
    "\n",
    "# import warnings\n",
    "\n",
    "# warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# class Wave:\n",
    "#     def __init__(self, data: pd.DataFrame, select_cols: List[str]):\n",
    "#         self.data: pd.DataFrame = data\n",
    "#         self.select_cols: List[str] = select_cols\n",
    "    \n",
    "#     def __str__(self):\n",
    "#         return str(self.data)\n",
    "\n",
    "# waves: List[Wave] = []\n",
    "\n",
    "# # Scoring dictionaries\n",
    "# normal_scoring = {\n",
    "#     'Rarely or none of the time (less than 1 day)': 0,\n",
    "#     'Some or little of the time (1-2 days)': 1,\n",
    "#     'Occasionally or a moderate amount of time (3-4 days)': 2,\n",
    "#     'All of the time (5-7 days)': 3\n",
    "# }\n",
    "\n",
    "# reverse_scoring = {\n",
    "#     'Rarely or none of the time (less than 1 day)': 3,\n",
    "#     'Some or little of the time (1-2 days)': 2,\n",
    "#     'Occasionally or a moderate amount of time (3-4 days)': 1,\n",
    "#     'All of the time (5-7 days)': 0\n",
    "# }\n",
    "\n",
    "# incidence = []\n",
    "\n",
    "# # Loop through each wave\n",
    "# for i in tqdm(range(1, 3), desc=\"Labelling Participants\"):\n",
    "#     url = 'CSV/wave' + str(i) + '_select.csv'\n",
    "#     data = pd.read_csv(url)\n",
    "\n",
    "#     # Header text for each column based on wave\n",
    "#     header = 'w' + str(i)\n",
    "    \n",
    "#     # Create the select columns\n",
    "#     select_cols = [header + col for col in cesd_col_names]\n",
    "\n",
    "#     # Filter rows based on valid CESD answers\n",
    "#     cesd_valid_answers = ['Rarely or none of the time (less than 1 day)',\n",
    "#                           'Some or little of the time (1-2 days)',\n",
    "#                           'Occasionally or a moderate amount of time (3-4 days)',\n",
    "#                           'All of the time (5-7 days)']\n",
    "    \n",
    "#     # Only keep rows where all select_cols have valid answers\n",
    "#     # new_data = data[data[select_cols].isin(cesd_valid_answers).all(axis=1)].fillna(data.mode(), inplace=True)\n",
    "#     new_data = data[data[select_cols].isin(cesd_valid_answers).all(axis=1)]\n",
    "    \n",
    "#     # Apply scoring to all CESD columns\n",
    "#     for idx, col in enumerate(select_cols):\n",
    "#         if idx == 4 or idx == 7:  # Reverse scoring for columns 5 and 8 (0-indexed as 4 and 7)\n",
    "#             new_data[col] = new_data[col].replace(reverse_scoring)\n",
    "#         else:\n",
    "#             new_data[col] = new_data[col].replace(normal_scoring)\n",
    "\n",
    "#     # Derive \"Depressed\" column: 1 if score >= 10, else 0\n",
    "#     new_data['score'] = new_data[select_cols].sum(axis=1)\n",
    "#     new_data['depressed'] = (new_data['score'] >= 10).astype(int)\n",
    "\n",
    "#     # Check which rows have NaN values\n",
    "#     nan_rows = new_data[new_data.isna().any(axis=1)]\n",
    "\n",
    "#     # Print rows with NaN values\n",
    "#     print(nan_rows)\n",
    "\n",
    "#     new_data.to_csv(f'CSV/wave{wave_num}_select_labelled.csv', index=False)\n",
    "\n",
    "#     percentage_depressed = if PLOT: plotter.get_percent_na(new_data['depressed'].replace(1, pd.NA))\n",
    "\n",
    "#     incidence.append(percentage_depressed)\n",
    "\n",
    "#     # Append the wave object to the list\n",
    "#     wave = Wave(new_data, select_cols)\n",
    "#     waves.append(wave)\n",
    "\n",
    "# for i in range(len(incidence)): print((f\"Wave {i+1}: {round(incidence[i], 3)}% depressed\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652e8b1e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3571aaf2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# import pandas as pd\n",
    "# from typing import List, Dict, Tuple\n",
    "# import warnings\n",
    "\n",
    "# warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# # Selecting column names for CESD-10 Scale related features\n",
    "# cesd_col_names = [\"_a_emobth\", \"_a_emomnd\", \"_a_emodep\", \"_a_emoeff\", \"_a_emohope\",\n",
    "#                 \"_a_emofear\", \"_a_emoslp\", \"_a_emohap\", \"_a_emolone\", \"_a_emogo\"]\n",
    "\n",
    "# for wave in range(len(waves)):\n",
    "#     print(f\"Wave {wave+1}:\")\n",
    "#     data: pd.DataFrame = waves[wave].data\n",
    "#     select_cols = waves[wave].get_select_cols()\n",
    "\n",
    "#     # Dictionary to store the scores and depression status\n",
    "#     scores: Dict[str, Dict] = dict()\n",
    "\n",
    "#     # Series containing participant IDs\n",
    "#     participants = data['pid']\n",
    "\n",
    "#     # Counter for the number of participants flagged as depressed\n",
    "#     count_depressed = 0\n",
    "\n",
    "#     # Iterate over each participant\n",
    "#     for participant in tqdm(participants, desc=\"Labelling Participants\"):\n",
    "#         score = 0\n",
    "#         depressed = False\n",
    "\n",
    "#         idx = data.index[data['pid'] == participant]\n",
    "\n",
    "#         # Sum the scores for all relevant columns\n",
    "#         for col in select_cols:\n",
    "#             value = data.at[idx[0], col]  # Accessing the value using participant ID and column name\n",
    "#             score += value\n",
    "\n",
    "#         # Determine if the participant is depressed based on the score\n",
    "#         if score >= 10:\n",
    "#             depressed = True\n",
    "#             count_depressed += 1\n",
    "\n",
    "#         # Map the participant ID to their score and depression status\n",
    "#         scores[participant] = {'score': int(score), 'Depressed': depressed}\n",
    "    \n",
    "#     data['depression_score'] = 0\n",
    "\n",
    "#     for i in cesd_col_names:\n",
    "#         data['depression_score'] += data[f\"w{wave+1}{i}\"]\n",
    "    \n",
    "#     # Create a new column 'new_column' based on a condition\n",
    "#     data['depressed'] = data['depression_score'].apply(lambda x: 1 if x >= 10 else 0)\n",
    "\n",
    "#     print(list(data['depressed']).count(1))\n",
    "\n",
    "#     data.to_csv('wave1_select_labelled.csv')\n",
    "#     # Print the total number of depressed participants\n",
    "#     print(f\"Total Depressed Participants: {count_depressed}\")\n",
    "#     print(f\"Calculated Prevalence for Depression: {round(count_depressed/len(participants) * 100, 2)}%\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2.583138,
   "end_time": "2024-10-02T16:51:14.161829",
   "environment_variables": {},
   "exception": null,
   "input_path": "PreProcessing.ipynb",
   "output_path": "waveNotebooks/output_notebook_wave_5.ipynb",
   "parameters": {
    "wave_param": 5
   },
   "start_time": "2024-10-02T16:51:11.578691",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}