{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b3a11ce",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [8]</a>'.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6140d39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T16:46:15.869322Z",
     "iopub.status.busy": "2024-10-02T16:46:15.867462Z",
     "iopub.status.idle": "2024-10-02T16:46:15.882089Z",
     "shell.execute_reply": "2024-10-02T16:46:15.880969Z"
    },
    "papermill": {
     "duration": 0.023964,
     "end_time": "2024-10-02T16:46:15.885384",
     "exception": false,
     "start_time": "2024-10-02T16:46:15.861420",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "param_name = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffa9daa6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T16:46:15.903918Z",
     "iopub.status.busy": "2024-10-02T16:46:15.903510Z",
     "iopub.status.idle": "2024-10-02T16:46:15.908510Z",
     "shell.execute_reply": "2024-10-02T16:46:15.906990Z"
    },
    "papermill": {
     "duration": 0.020631,
     "end_time": "2024-10-02T16:46:15.910576",
     "exception": false,
     "start_time": "2024-10-02T16:46:15.889945",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "param_name = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c14880",
   "metadata": {
    "papermill": {
     "duration": 0.005229,
     "end_time": "2024-10-02T16:46:15.924230",
     "exception": false,
     "start_time": "2024-10-02T16:46:15.919001",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing\n",
    "\n",
    "Each wave must be preprocessed. This will include:\n",
    "- Assigning labels according to the CESD-10 reporting scale\n",
    "- Discretizing/classing continuous variables\n",
    "- Feature Selection/Engineering\n",
    "- Normalisation/Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5482818a",
   "metadata": {
    "papermill": {
     "duration": 0.007753,
     "end_time": "2024-10-02T16:46:15.936622",
     "exception": false,
     "start_time": "2024-10-02T16:46:15.928869",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Preparation\n",
    "\n",
    "This includes:\n",
    "1. Collecting each wave's .csv file\n",
    "2. Renaming columns to make them more useable\n",
    "3. Type fixing (Eg. Changing Date to datetime)\n",
    "4. Incomplete data dropping (For the purpose of this Research, we only include data from participants who were 'Successfully Interviewed')\n",
    "\n",
    "**This notebook requires the user to specify which wave number to preprocess at the beginning of the file. Thus, for all 5 waves it must be run separately. Thereafter, the labeller.py file must be run to apply labels and generate labelled csv files.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6f38ed2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T16:46:15.955505Z",
     "iopub.status.busy": "2024-10-02T16:46:15.948067Z",
     "iopub.status.idle": "2024-10-02T16:46:17.318266Z",
     "shell.execute_reply": "2024-10-02T16:46:17.317261Z"
    },
    "papermill": {
     "duration": 1.378991,
     "end_time": "2024-10-02T16:46:17.320171",
     "exception": false,
     "start_time": "2024-10-02T16:46:15.941180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotter\n",
    "import importlib\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bd5dd62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T16:46:17.331275Z",
     "iopub.status.busy": "2024-10-02T16:46:17.330897Z",
     "iopub.status.idle": "2024-10-02T16:46:20.245295Z",
     "shell.execute_reply": "2024-10-02T16:46:20.244325Z"
    },
    "papermill": {
     "duration": 2.922626,
     "end_time": "2024-10-02T16:46:20.247112",
     "exception": false,
     "start_time": "2024-10-02T16:46:17.324486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_161753/818341011.py:12: DtypeWarning: Columns (7,8,9,10,11,14,18,19,26,30,31,32,33,34,37,39,41,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,60,61,62,63,64,65,66,68,69,70,71,72,73,74,76,77,78,79,80,81,82,84,85,86,87,88,89,90,92,93,94,95,96,97,98,100,101,102,103,104,105,106,108,109,110,111,112,113,114,116,117,118,119,120,121,122,124,125,126,127,128,129,130,132,133,134,135,136,137,138,140,141,142,143,144,145,146,148,149,150,151,152,153,154,156,157,158,159,160,161,162,164,165,166,167,168,169,170,172,173,174,177,178,181,182,183,184,185,186,187,190,194,195,196,197,198,199,201,203,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,234,235,236,237,238,239,240,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,265,266,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,295,297,299,300,301,302,303,304,305,306,307,308,309,311,312,313,314,315,316,317,319,320,321,322,323,324,325,327,328,329,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,363,367,369,375,379,381,383,385,387,389,391,393,395,401,402,403,404,405,406,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,438,439,440,441,442,443,444,445,446,453,454,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,489,490,491,492,494,495,496,501,502,503,504,505,506,507,508,513,514,515,516,529,530,532,533,536,538,539,541,542,544,545,547,548,550,551,553,554,556,557,559,560,566,573,574,576,577,578,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,598,599,600,601,602,604,605,606,607,608,609,610,611,645,646,647,648,649,650,651,653,654,655,657,658,659,661,662,663,665,666,667,669,670,671,673,675,677,678,679,680,681,690,691,692,697,708,709,710,711,712,713,714,715,717,724,729,740,749,750,751,752,753,758,759,760) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df: pd.DataFrame = pd.read_csv(path_to_file)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w3_hhid</th>\n",
       "      <th>pid</th>\n",
       "      <th>w3_a_outcome</th>\n",
       "      <th>w3_a_intrv_c</th>\n",
       "      <th>w3_a_intrv_d</th>\n",
       "      <th>w3_a_intrv_m</th>\n",
       "      <th>w3_a_intrv_y</th>\n",
       "      <th>w3_a_refexpl</th>\n",
       "      <th>w3_a_refexpl_o</th>\n",
       "      <th>w3_a_refint</th>\n",
       "      <th>...</th>\n",
       "      <th>w3_a_intlng4</th>\n",
       "      <th>w3_a_intlng5</th>\n",
       "      <th>w3_a_intlng6</th>\n",
       "      <th>w3_a_intresp</th>\n",
       "      <th>w3_a_intrespact</th>\n",
       "      <th>w3_a_intresphear</th>\n",
       "      <th>w3_a_intrespque</th>\n",
       "      <th>w3_a_intresppid1</th>\n",
       "      <th>w3_a_intresppid2</th>\n",
       "      <th>w3_a_intresppid3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>305985</td>\n",
       "      <td>591460</td>\n",
       "      <td>Successfully Interviewed</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>1st</td>\n",
       "      <td>May</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hostile</td>\n",
       "      <td>Not at all attentive</td>\n",
       "      <td>No other person within hearing range at any time</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>305366</td>\n",
       "      <td>310896</td>\n",
       "      <td>Successfully Interviewed</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>1st</td>\n",
       "      <td>July</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hostile</td>\n",
       "      <td>Not at all attentive</td>\n",
       "      <td>No other person within hearing range at any time</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>306655</td>\n",
       "      <td>305742</td>\n",
       "      <td>Successfully Interviewed</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1st</td>\n",
       "      <td>August</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Friendly</td>\n",
       "      <td>Very attentive</td>\n",
       "      <td>No other person within hearing range at any time</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>308518</td>\n",
       "      <td>319422</td>\n",
       "      <td>Successfully Interviewed</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>17th</td>\n",
       "      <td>June</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hostile</td>\n",
       "      <td>Not at all attentive</td>\n",
       "      <td>No other person within hearing range at any time</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>302517</td>\n",
       "      <td>734555</td>\n",
       "      <td>Successfully Interviewed</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>28th</td>\n",
       "      <td>July</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Friendly</td>\n",
       "      <td>Very attentive</td>\n",
       "      <td>No other person within hearing range at any time</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22452</th>\n",
       "      <td>303186</td>\n",
       "      <td>317569</td>\n",
       "      <td>Successfully Interviewed</td>\n",
       "      <td>58.0</td>\n",
       "      <td>29th</td>\n",
       "      <td>October</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Friendly</td>\n",
       "      <td>Very attentive</td>\n",
       "      <td>1+ persons within hearing range for part of th...</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22453</th>\n",
       "      <td>302272</td>\n",
       "      <td>303655</td>\n",
       "      <td>Successfully Interviewed</td>\n",
       "      <td>40.0</td>\n",
       "      <td>10th</td>\n",
       "      <td>June</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Friendly</td>\n",
       "      <td>Very attentive</td>\n",
       "      <td>1+ persons within hearing range for all of the...</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22454</th>\n",
       "      <td>309933</td>\n",
       "      <td>317568</td>\n",
       "      <td>Successfully Interviewed</td>\n",
       "      <td>82.0</td>\n",
       "      <td>31st</td>\n",
       "      <td>October</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Friendly</td>\n",
       "      <td>Very attentive</td>\n",
       "      <td>1+ persons within hearing range for all of the...</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22455</th>\n",
       "      <td>307026</td>\n",
       "      <td>312007</td>\n",
       "      <td>Successfully Interviewed</td>\n",
       "      <td>28.0</td>\n",
       "      <td>22nd</td>\n",
       "      <td>August</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Friendly</td>\n",
       "      <td>Not at all attentive</td>\n",
       "      <td>No other person within hearing range at any time</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22456</th>\n",
       "      <td>301678</td>\n",
       "      <td>314049</td>\n",
       "      <td>Successfully Interviewed</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18th</td>\n",
       "      <td>September</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Friendly</td>\n",
       "      <td>Very attentive</td>\n",
       "      <td>No other person within hearing range at any time</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18689 rows × 761 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       w3_hhid     pid              w3_a_outcome  w3_a_intrv_c w3_a_intrv_d  \\\n",
       "481     305985  591460  Successfully Interviewed        1002.0          1st   \n",
       "815     305366  310896  Successfully Interviewed        1002.0          1st   \n",
       "818     306655  305742  Successfully Interviewed          70.0          1st   \n",
       "1052    308518  319422  Successfully Interviewed        1002.0         17th   \n",
       "1406    302517  734555  Successfully Interviewed        1002.0         28th   \n",
       "...        ...     ...                       ...           ...          ...   \n",
       "22452   303186  317569  Successfully Interviewed          58.0         29th   \n",
       "22453   302272  303655  Successfully Interviewed          40.0         10th   \n",
       "22454   309933  317568  Successfully Interviewed          82.0         31st   \n",
       "22455   307026  312007  Successfully Interviewed          28.0         22nd   \n",
       "22456   301678  314049  Successfully Interviewed           4.0         18th   \n",
       "\n",
       "      w3_a_intrv_m  w3_a_intrv_y w3_a_refexpl w3_a_refexpl_o w3_a_refint  ...  \\\n",
       "481            May        2012.0          NaN            NaN         NaN  ...   \n",
       "815           July        2012.0          NaN            NaN         NaN  ...   \n",
       "818         August        2012.0          NaN            NaN         NaN  ...   \n",
       "1052          June        2012.0          NaN            NaN         NaN  ...   \n",
       "1406          July        2012.0          NaN            NaN         NaN  ...   \n",
       "...            ...           ...          ...            ...         ...  ...   \n",
       "22452      October        2012.0          NaN            NaN         NaN  ...   \n",
       "22453         June        2012.0          NaN            NaN         NaN  ...   \n",
       "22454      October        2012.0          NaN            NaN         NaN  ...   \n",
       "22455       August        2012.0          NaN            NaN         NaN  ...   \n",
       "22456    September        2012.0          NaN            NaN         NaN  ...   \n",
       "\n",
       "      w3_a_intlng4 w3_a_intlng5  w3_a_intlng6 w3_a_intresp  \\\n",
       "481            NaN          NaN           NaN      Hostile   \n",
       "815            NaN          NaN           NaN      Hostile   \n",
       "818            NaN          NaN           NaN     Friendly   \n",
       "1052           NaN          NaN           NaN      Hostile   \n",
       "1406           NaN          NaN           NaN     Friendly   \n",
       "...            ...          ...           ...          ...   \n",
       "22452          NaN          NaN           NaN     Friendly   \n",
       "22453          NaN          NaN           NaN     Friendly   \n",
       "22454          NaN          NaN           NaN     Friendly   \n",
       "22455          NaN          NaN           NaN     Friendly   \n",
       "22456          NaN          NaN           NaN     Friendly   \n",
       "\n",
       "            w3_a_intrespact  \\\n",
       "481    Not at all attentive   \n",
       "815    Not at all attentive   \n",
       "818          Very attentive   \n",
       "1052   Not at all attentive   \n",
       "1406         Very attentive   \n",
       "...                     ...   \n",
       "22452        Very attentive   \n",
       "22453        Very attentive   \n",
       "22454        Very attentive   \n",
       "22455  Not at all attentive   \n",
       "22456        Very attentive   \n",
       "\n",
       "                                        w3_a_intresphear w3_a_intrespque  \\\n",
       "481     No other person within hearing range at any time              No   \n",
       "815     No other person within hearing range at any time              No   \n",
       "818     No other person within hearing range at any time              No   \n",
       "1052    No other person within hearing range at any time              No   \n",
       "1406    No other person within hearing range at any time              No   \n",
       "...                                                  ...             ...   \n",
       "22452  1+ persons within hearing range for part of th...              No   \n",
       "22453  1+ persons within hearing range for all of the...              No   \n",
       "22454  1+ persons within hearing range for all of the...              No   \n",
       "22455   No other person within hearing range at any time              No   \n",
       "22456   No other person within hearing range at any time              No   \n",
       "\n",
       "      w3_a_intresppid1 w3_a_intresppid2 w3_a_intresppid3  \n",
       "481                NaN              NaN              NaN  \n",
       "815                NaN              NaN              NaN  \n",
       "818                NaN              NaN              NaN  \n",
       "1052               NaN              NaN              NaN  \n",
       "1406               NaN              NaN              NaN  \n",
       "...                ...              ...              ...  \n",
       "22452              NaN              NaN              NaN  \n",
       "22453              NaN              NaN              NaN  \n",
       "22454              NaN              NaN              NaN  \n",
       "22455              NaN              NaN              NaN  \n",
       "22456              NaN              NaN              NaN  \n",
       "\n",
       "[18689 rows x 761 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(plotter)\n",
    "\n",
    "# Parameters\n",
    "\n",
    "# wave_num = int(input(\"Enter wave to be processed: \"))\n",
    "wave_num = int(param_name)\n",
    "\n",
    "PLOT = 0\n",
    "\n",
    "path_to_file = f\"WaveFiles/wave{wave_num}.csv\"\n",
    "\n",
    "df: pd.DataFrame = pd.read_csv(path_to_file)\n",
    "\n",
    "# Selecting column names for CESD-10 Scale related features\n",
    "cesd_col_names = [\"_a_emobth\", \"_a_emomnd\", \"_a_emodep\", \"_a_emoeff\", \"_a_emohope\",\n",
    "                \"_a_emofear\", \"_a_emoslp\", \"_a_emohap\", \"_a_emolone\", \"_a_emogo\"]\n",
    "# for i in range(len(cesd_col_names)): cesd_col_names[i] = f\"w{wave_num}\" + cesd_col_names[i]\n",
    "\n",
    "# Columns relating to non-employment based income sources. EXCLUDED: incwar_v, inco\n",
    "other_incomes = [\"incgovpen_v\", \"incppen_v\", \"incret_v\", \"incretp_v\", \"incuif_v\",\n",
    "                 \"incwc_v\", \"incdis_v\", \"incchld_v\", \"incfos_v\", \"inccare_v\",\n",
    "                 \"incint_v\", \"incinh_v\", \"incrnt_v\", \"incretr_v\",\n",
    "                 \"inclob_v\", \"incgif_v\", \"incloan_v\", \"incsale_v\"]\n",
    "for i in range(len(other_incomes)): other_incomes[i] = f\"w{wave_num}_a_\" + other_incomes[i]\n",
    "\n",
    "new_df = pd.DataFrame({})\n",
    "\n",
    "curr_year = 0\n",
    "if wave_num == 1: curr_year = '08'\n",
    "if wave_num == 2: curr_year = '10'\n",
    "if wave_num == 3: curr_year = '12'\n",
    "if wave_num == 4: curr_year = '14'\n",
    "if wave_num == 5: curr_year = '17'\n",
    "\n",
    "# Rename specific columns\n",
    "df = df.rename(columns={f'w{wave_num}_a_gen': 'gender',\n",
    "                        f'w{wave_num}_a_dob_y': 'birth_year',\n",
    "                        f'w{wave_num}_a_popgrp': 'race',\n",
    "                        f'w{wave_num}_a_marstt': 'marital_status',\n",
    "                        f'w{wave_num}_a_brnprov': 'born_province',\n",
    "\n",
    "                        f'w{wave_num}_a_mthali': 'parents_alive',\n",
    "\n",
    "                        f'w{wave_num}_a_em1': 'employed',\n",
    "                        f'w{wave_num}_a_em1pay': 'employed_take_home',\n",
    "                        f'w{wave_num}_a_em1hrs': 'employed_weekly_hours',\n",
    "                        f'w{wave_num}_a_ems': 'self_employed',\n",
    "                        f'w{wave_num}_a_emsincmn': 'self_employed_take_home',\n",
    "                        f'w{wave_num}_a_emshrs': 'self_employed_weekly_hours',\n",
    "                        f'w{wave_num}_a_emc': 'casual_work',\n",
    "                        f'w{wave_num}_a_emchrs': 'casual_weekly_hours',\n",
    "\n",
    "                        f'w{wave_num}_a_edschgrd': 'highest_grade_school',\n",
    "                        f'w{wave_num}_a_edter': 'tertiary_education',\n",
    "                        # f'w{wave_num}_a_ed07att': 'attended_courses',\n",
    "                        f'w{wave_num}_a_ed{curr_year}cur': 'currently_enrolled',\n",
    "\n",
    "                        f'w{wave_num}_a_hldes': 'health_status',\n",
    "                        f'w{wave_num}_a_hlcon': 'time_since_prev_consulation',\n",
    "                        f'w{wave_num}_a_hlconmed': 'medicine_prescribed_at_prev_consulation',\n",
    "\n",
    "                        f\"w{wave_num}_a_hl30fl\": \"flu_symptoms\",\n",
    "                        f\"w{wave_num}_a_hl30fev\": \"fever\",\n",
    "                        f\"w{wave_num}_a_hl30pc\": \"persistent_cough\",\n",
    "                        f\"w{wave_num}_a_hl30cb\": \"cough_with_blood\",\n",
    "                        f\"w{wave_num}_a_hl30tc\": \"tight_chest\",\n",
    "                        f\"w{wave_num}_a_hl30cp\": \"chest_pain\",\n",
    "                        f\"w{wave_num}_a_hl30b\": \"body_ache\",\n",
    "                        f\"w{wave_num}_a_hl30h\": \"headache\",\n",
    "                        f\"w{wave_num}_a_hl30ba\": \"back_ache\",\n",
    "                        f\"w{wave_num}_a_hl30jp\": \"joint_pain_arthritis\",\n",
    "                        f\"w{wave_num}_a_hl30v\": \"vomiting\",\n",
    "                        f\"w{wave_num}_a_hl30d\": \"diarrhoea\",\n",
    "                        f\"w{wave_num}_a_hl30w\": \"felt_weak\",\n",
    "                        f\"w{wave_num}_a_hl30pua\": \"pain_in_upper_abdomen\",\n",
    "                        f\"w{wave_num}_a_hl30pla\": \"pain_in_lower_abdomen\",\n",
    "                        f\"w{wave_num}_a_hl30pu\": \"painful_urination\",\n",
    "                        f\"w{wave_num}_a_hl30sa\": \"swelling_ankles\",\n",
    "                        f\"w{wave_num}_a_hl30r\": \"rash\",\n",
    "                        f\"w{wave_num}_a_hl30sd\": \"skin_disorders\",\n",
    "                        f\"w{wave_num}_a_hl30c\": \"conjunctivitis_eye_infection\",\n",
    "                        f\"w{wave_num}_a_hl30wl\": \"severe_weight_loss\",\n",
    "                        f\"w{wave_num}_a_hl30ye\": \"yellow_eyes\",\n",
    "                        f\"w{wave_num}_a_hl30ml\": \"memory_loss\",\n",
    "                        f\"w{wave_num}_a_hl30i\": \"serious_injury\",\n",
    "\n",
    "                        f\"w{wave_num}_a_hltb\": \"had_tubercolosis\",\n",
    "                        f\"w{wave_num}_a_hlbp\": \"had_high_blood_pressure\",\n",
    "                        f\"w{wave_num}_a_hldia\": \"had_diabetes_or_high_blood_sugar\",\n",
    "                        f\"w{wave_num}_a_hlstrk\": \"had_stroke\",\n",
    "                        f\"w{wave_num}_a_hlast\": \"had_asthma\",\n",
    "                        f\"w{wave_num}_a_hlhrt\": \"had_heart_problems\",\n",
    "                        f\"w{wave_num}_a_hlcan\": \"had_cancer\",\n",
    "                        f\"w{wave_num}_a_hltb_yr\": \"tb_diagnosis_year\",\n",
    "                        f\"w{wave_num}_a_hlbp_yr\": \"hbp_diagnosis_year\",\n",
    "                        f\"w{wave_num}_a_hldia_yr\": \"dia_diagnosis_year\",\n",
    "                        f\"w{wave_num}_a_hlstrk_yr\": \"strk_diagnosis_year\",\n",
    "                        f\"w{wave_num}_a_hlast_yr\": \"ast_diagnosis_year\",\n",
    "                        f\"w{wave_num}_a_hlhrt_yr\": \"hrt_diagnosis_year\",\n",
    "                        f\"w{wave_num}_a_hlcan_yr\": \"can_diagnosis_year\",\n",
    "\n",
    "                        f\"w{wave_num}_a_hllfexer\": \"exercise_frequency\",\n",
    "                        f\"w{wave_num}_a_hllfsmk\": \"smokes_cigarettes\",\n",
    "                        f\"w{wave_num}_a_hllfalc\": \"alcohol_frequency\",\n",
    "                        f\"w{wave_num}_a_hllfalcqnt\": \"alcohol_quantity\",\n",
    "\n",
    "                        f'w{wave_num}_a_height_1': \"height_measurement\",\n",
    "                        f'w{wave_num}_a_weight_1': \"weight_measurement\",\n",
    "                        f'w{wave_num}_a_waist_1': \"waist_measurement\",\n",
    "                        })\n",
    "\n",
    "outcome_str = f'w{wave_num}_a_outcome'\n",
    "new_data = df[df[outcome_str] == 'Successfully Interviewed']\n",
    "\n",
    "if wave_num == 2: new_data = new_data[new_data['w2_a_phase'] == 'Phase 1']\n",
    "\n",
    "df = new_data\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8f203e",
   "metadata": {
    "papermill": {
     "duration": 0.004911,
     "end_time": "2024-10-02T16:46:20.256920",
     "exception": false,
     "start_time": "2024-10-02T16:46:20.252009",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c28a6c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T16:46:20.275932Z",
     "iopub.status.busy": "2024-10-02T16:46:20.275552Z",
     "iopub.status.idle": "2024-10-02T16:46:20.283094Z",
     "shell.execute_reply": "2024-10-02T16:46:20.281723Z"
    },
    "papermill": {
     "duration": 0.019517,
     "end_time": "2024-10-02T16:46:20.284958",
     "exception": false,
     "start_time": "2024-10-02T16:46:20.265441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "PID : Integer\n",
    "\n",
    "Uniquely identifes each participant. We have to include this to ensure that when deriving new columns, we index by pid.\n",
    "So that each value in the new column is correctly associated with the partcipant\n",
    "'''\n",
    "new_df['pid'] = df['pid']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61358a78",
   "metadata": {
    "papermill": {
     "duration": 0.00468,
     "end_time": "2024-10-02T16:46:20.294364",
     "exception": false,
     "start_time": "2024-10-02T16:46:20.289684",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Section B: Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b416358",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T16:46:20.312004Z",
     "iopub.status.busy": "2024-10-02T16:46:20.311532Z",
     "iopub.status.idle": "2024-10-02T16:46:20.336030Z",
     "shell.execute_reply": "2024-10-02T16:46:20.334660Z"
    },
    "papermill": {
     "duration": 0.037066,
     "end_time": "2024-10-02T16:46:20.338018",
     "exception": false,
     "start_time": "2024-10-02T16:46:20.300952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pid    18689\n",
      "age    18686\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Temporary dataframe used to mainting indexing when deriving new columns\n",
    "temp_df = pd.DataFrame({})\n",
    "\n",
    "'''\n",
    "AGE (Derived) : Integer\n",
    "\n",
    "Provides the age of the participant at the time of the interview.\n",
    "'''\n",
    "# Calculated age by taking interview year minus year of birth\n",
    "years: pd.Series = df['birth_year'].replace('Missing', pd.NA).replace(\"Don't know\", pd.NA).replace(\"Refused\", pd.NA).dropna()\n",
    "# years = years.fillna(years.mode()[0])\n",
    "df['age'] = df[f'w{wave_num}_a_intrv_y'] - years.astype(float)\n",
    "new_df['age'] = df['age'].astype('Int32')\n",
    "\n",
    "if PLOT: plotter.plot_histogram(new_df['age'], \"Distribution of Age\")\n",
    "\n",
    "print(new_df.count())\n",
    "\n",
    "'''\n",
    "GENDER : Integer (Class)\n",
    "\n",
    "Factorizes gender.\n",
    "'''\n",
    "temp_df['gender'], getGender = pd.factorize(df['gender'])\n",
    "# print(\"GENDER:\", getGender,\"\\n\", temp_df['gender'].unique())\n",
    "\n",
    "# fig, axs = plt.subplots(1, 2, figsize=(14, 4))\n",
    "if PLOT: plotter.plot_bar(df['gender'], title=\"gender\", log_scale=False)\n",
    "\n",
    "new_df['gender'] = temp_df['gender'].fillna(temp_df['gender'].mode()[0])\n",
    "\n",
    "# # Check which rows have NaN values\n",
    "# nan_rows = new_df[new_df.isna().any(axis=1)]\n",
    "\n",
    "# # Print rows with NaN values\n",
    "# print(nan_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75c9501e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T16:46:20.355112Z",
     "iopub.status.busy": "2024-10-02T16:46:20.354618Z",
     "iopub.status.idle": "2024-10-02T16:46:20.440848Z",
     "shell.execute_reply": "2024-10-02T16:46:20.414460Z"
    },
    "papermill": {
     "duration": 0.10048,
     "end_time": "2024-10-02T16:46:20.443520",
     "exception": false,
     "start_time": "2024-10-02T16:46:20.343040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RACE: Index(['African', 'Coloured', 'Asian/Indian', 'White'], dtype='object') \n",
      " [0 1 2 3]\n",
      "MARITAL_STATUS: Index(['Married', 'Never married', 'Widow/Widower', 'Missing',\n",
      "       'Living with partner', 'Divorced or separated', 'Don't know',\n",
      "       'Refused'],\n",
      "      dtype='object') \n",
      " [0 1 2 3 4 5 6 7]\n",
      "BORN_PROVINCE: Index(['Eastern Cape', 'Northern Cape', 'Limpopo', 'KwaZulu-Natal',\n",
      "       'Western Cape', 'Mpumalanga', 'Free State', 'Gauteng', 'North West',\n",
      "       'Outside RSA', 'Don't know'],\n",
      "      dtype='object') \n",
      " ['Eastern Cape' 'Northern Cape' 'Limpopo' 'KwaZulu-Natal' 'Western Cape'\n",
      " 'Mpumalanga' 'Free State' 'Gauteng' 'North West' 'Outside RSA'\n",
      " \"Don't know\"]\n",
      "pid               18689\n",
      "age               18686\n",
      "gender            14924\n",
      "race              14924\n",
      "marital_status    14924\n",
      "born_province     14924\n",
      "dtype: int64\n",
      "pid               18689\n",
      "age               18686\n",
      "gender            14924\n",
      "race              14924\n",
      "marital_status    14924\n",
      "born_province     14924\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "RACE : Integer (Class)\n",
    "\n",
    "Any nan or missing entries were replaced with the class \"Other\". This helps retain as much info as possible.\n",
    "'''\n",
    "# Combined Nan and Missing entries together as their own class and factorized\n",
    "df['race'] = df['race'].replace(pd.NA, 'Other').replace('Missing', 'Other')\n",
    "temp_df['race'], getRace = pd.factorize(df['race'])\n",
    "print(\"RACE:\", getRace,\"\\n\", temp_df['race'].unique())\n",
    "\n",
    "if PLOT: plotter.plot_bar(df['race'], title=\"Race before sampling\", log_scale=False)\n",
    "\n",
    "new_df['race'] = temp_df['race']\n",
    "\n",
    "'''\n",
    "MARITAL_STATUS : Integer (Class)\n",
    "\n",
    "Includes missing as an option/value.\n",
    "'''\n",
    "temp_df['marital_status'], getMaritalStatus = pd.factorize(df['marital_status'])\n",
    "print(\"MARITAL_STATUS:\", getMaritalStatus,\"\\n\", temp_df['marital_status'].unique())\n",
    "\n",
    "if PLOT: plotter.plot_bar(df['marital_status'], title=\"Marital Status\", log_scale=False, rotation=45)\n",
    "\n",
    "new_df['marital_status'] = temp_df['marital_status']\n",
    "\n",
    "'''\n",
    "BORN_PROVINCE : Integer (Class)\n",
    "\n",
    "Replaced Nan values with Missing. Importantly, about half of wave 1 seem to \n",
    "'''\n",
    "\n",
    "df['born_province'] = df['born_province'].replace(pd.NA, \"Missing\")\n",
    "# df['born_province'] = df['born_province'].dropna()\n",
    "temp_df['born_province'], getBornProvince = pd.factorize(df['born_province'])\n",
    "print(\"BORN_PROVINCE:\", getBornProvince,\"\\n\", df['born_province'].unique())\n",
    "\n",
    "if PLOT: plotter.plot_bar(df['born_province'], title=\"Born Province\", log_scale=False, rotation=90)\n",
    "\n",
    "new_df['born_province'] = temp_df['born_province']\n",
    "\n",
    "print(new_df.count())\n",
    "\n",
    "new_df = new_df.fillna(new_df.mode())\n",
    "\n",
    "print(new_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ede619",
   "metadata": {
    "papermill": {
     "duration": 0.013591,
     "end_time": "2024-10-02T16:46:20.464638",
     "exception": false,
     "start_time": "2024-10-02T16:46:20.451047",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Section C1: Children ever born (Only for Females)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f329ab",
   "metadata": {
    "papermill": {
     "duration": 0.01545,
     "end_time": "2024-10-02T16:46:20.519236",
     "exception": false,
     "start_time": "2024-10-02T16:46:20.503786",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Section D: Parents’ education, living arrangements and vital status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57d3186",
   "metadata": {
    "papermill": {
     "duration": 0.012462,
     "end_time": "2024-10-02T16:46:20.545323",
     "exception": false,
     "start_time": "2024-10-02T16:46:20.532861",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Section E: Labour market participation\n",
    "\n",
    "Also includes Section F1: Individual income from non-employment sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e739cb3d",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffd5bda7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T16:46:20.565753Z",
     "iopub.status.busy": "2024-10-02T16:46:20.565421Z",
     "iopub.status.idle": "2024-10-02T16:46:21.972085Z",
     "shell.execute_reply": "2024-10-02T16:46:21.970860Z"
    },
    "papermill": {
     "duration": 1.421201,
     "end_time": "2024-10-02T16:46:21.973382",
     "exception": true,
     "start_time": "2024-10-02T16:46:20.552181",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMPLOYED: Index(['No', 'Yes', 'Refused', 'Don't know'], dtype='object') \n",
      " [0 1 2 3]\n",
      "SELF_EMPLOYED: Index(['Yes', 'No', 'Refused', 'Don't know'], dtype='object') \n",
      " [0 1 2 3]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'self_employed_take_home'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'self_employed_take_home'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 62\u001b[0m\n\u001b[1;32m     55\u001b[0m new_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mself_employed\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m temp_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mself_employed\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03mSELF_EMPLOYED_TAKE_HOME : FLOAT -> Integer (Class)\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03mReplaced any item that was a string or NA with 0. The amounts are discretized into bins.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mself_employed_take_home\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mself_employed_take_home\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0.0\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRefused\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.0\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDon\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt know\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.0\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(pd\u001b[38;5;241m.\u001b[39mNA, \u001b[38;5;241m0.0\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot Applicable\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.0\u001b[39m)\n\u001b[1;32m     64\u001b[0m temp_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mself_employed_take_home\u001b[39m\u001b[38;5;124m'\u001b[39m], getSelfEmployedTakeHome \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mfactorize(pd\u001b[38;5;241m.\u001b[39mcut(pd\u001b[38;5;241m.\u001b[39mto_numeric(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mself_employed_take_home\u001b[39m\u001b[38;5;124m'\u001b[39m]), bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m))\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m PLOT: plotter\u001b[38;5;241m.\u001b[39mplot_histogram(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mself_employed_take_home\u001b[39m\u001b[38;5;124m'\u001b[39m], title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelf Employed Monthly Earnings\u001b[39m\u001b[38;5;124m\"\u001b[39m, log_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, rotation\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m90\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'self_employed_take_home'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "EMPLOYED : Integer (Class)\n",
    "\n",
    "1 or 0 if participant is employed at some company. Missing replaced with Refused since both indicate similar decisions\n",
    "'''\n",
    "df['employed'] = df['employed'].replace('Missing', 'Refused')\n",
    "temp_df['employed'], getEmployedBool = pd.factorize(df['employed'])\n",
    "print(\"EMPLOYED:\", getEmployedBool,\"\\n\", temp_df['employed'].unique())\n",
    "\n",
    "if PLOT: plotter.plot_bar(df['employed'], title=\"Employed by Company\", log_scale=False, rotation=0)\n",
    "\n",
    "new_df['employed'] = temp_df['employed']\n",
    "\n",
    "'''\n",
    "EMPLOYED_TAKE_HOME : FLOAT -> Integer (Class)\n",
    "\n",
    "Replaced any item that was a string or NA with 0. The amounts are discretized into bins.\n",
    "'''\n",
    "df['employed_take_home'] = df['employed_take_home'].replace('Missing', 0.0).replace(\"Refused\", 0.0).replace(\"Don't know\", 0.0).replace(pd.NA, 0.0).replace(\"Not Applicable\", 0.0)\n",
    "\n",
    "temp_df['employed_take_home'], getEmployedTakeHome = pd.factorize(pd.cut(pd.to_numeric(df['employed_take_home']), bins=30))\n",
    "\n",
    "if PLOT: plotter.plot_histogram(temp_df['employed_take_home'], title=\"Employed Monthly Earnings\", log_scale=True, rotation=90)\n",
    "\n",
    "new_df['employed_take_home'] = temp_df['employed_take_home']\n",
    "\n",
    "'''\n",
    "EMPLOYED_WEEKLY_HOURS : Integer\n",
    "\n",
    "Replaced any item that was a string or NA with 0. I haven't binned this feature since Hours worked weekly will have frequent hour amounts.\n",
    "'''\n",
    "df['employed_weekly_hours'] = df['employed_weekly_hours'].replace('Missing', 0).replace(\"Refused\", 0).replace(\"Don't know\", 0).replace(pd.NA, 0).replace(\"Not Applicable\", 0)\n",
    "df['employed_weekly_hours'] =  pd.to_numeric(df['employed_weekly_hours']).astype('Int32')\n",
    "\n",
    "# CAPPED ENTRIES WHERE EMPLOYED WEEKLY HOURS IS GREATER THAN 100\n",
    "# IF A PARTICIPANT HAS MORE THAN 100 HOURS WORKED, THIS GETS CLIPPED DOWN TO 100\n",
    "temp_df['employed_weekly_hours'] = df['employed_weekly_hours'].clip(upper=100)\n",
    "\n",
    "if PLOT: plotter.plot_histogram(temp_df['employed_weekly_hours'], title=\"Employed Weekly Hours Worked\", log_scale=False, rotation=0)\n",
    "\n",
    "new_df['employed_weekly_hours'] = temp_df['employed_weekly_hours'] \n",
    "\n",
    "\n",
    "'''\n",
    "SELF_EMPLOYED : Integer (Class)\n",
    "\n",
    "1 or 0 if participant is self employed. Missing replaced with Refused since both indicate similar decisions\n",
    "'''\n",
    "df['self_employed'] = df['self_employed'].replace('Missing', 'Refused')\n",
    "temp_df['self_employed'], getSelfEmployedBool = pd.factorize(df['self_employed'])\n",
    "print(\"SELF_EMPLOYED:\", getSelfEmployedBool,\"\\n\", temp_df['self_employed'].unique())\n",
    "\n",
    "if PLOT: plotter.plot_bar(df['self_employed'], title=\"Self Employed\", log_scale=False, rotation=0)\n",
    "\n",
    "new_df['self_employed'] = temp_df['self_employed']\n",
    "\n",
    "'''\n",
    "SELF_EMPLOYED_TAKE_HOME : FLOAT -> Integer (Class)\n",
    "\n",
    "Replaced any item that was a string or NA with 0. The amounts are discretized into bins.\n",
    "'''\n",
    "df['self_employed_take_home'] = df['self_employed_take_home'].replace('Missing', 0.0).replace(\"Refused\", 0.0).replace(\"Don't know\", 0.0).replace(pd.NA, 0.0).replace(\"Not Applicable\", 0.0)\n",
    "\n",
    "temp_df['self_employed_take_home'], getSelfEmployedTakeHome = pd.factorize(pd.cut(pd.to_numeric(df['self_employed_take_home']), bins=30))\n",
    "\n",
    "if PLOT: plotter.plot_histogram(df['self_employed_take_home'], title=\"Self Employed Monthly Earnings\", log_scale=True, rotation=90)\n",
    "\n",
    "new_df['self_employed_take_home'] = temp_df['self_employed_take_home']\n",
    "\n",
    "'''\n",
    "EMPLOYED_WEEKLY_HOURS : Integer\n",
    "\n",
    "Replaced any item that was a string or NA with 0. I haven't binned this feature since Hours worked weekly will have frequent hour amounts.\n",
    "'''\n",
    "df['self_employed_weekly_hours'] = df['self_employed_weekly_hours'].replace('Missing', 0).replace(\"Refused\", 0).replace(\"Don't know\", 0).replace(pd.NA, 0).replace(\"Not Applicable\", 0)\n",
    "df['self_employed_weekly_hours'] =  pd.to_numeric(df['self_employed_weekly_hours']).astype('Int32')\n",
    "\n",
    "# CAPPED ENTRIES WHERE EMPLOYED WEEKLY HOURS IS GREATER THAN 100\n",
    "# IF A PARTICIPANT HAS MORE THAN 100 HOURS WORKED, THIS GETS CLIPPED DOWN TO 100\n",
    "temp_df['self_employed_weekly_hours'] = df['self_employed_weekly_hours'].clip(upper=100)\n",
    "\n",
    "if PLOT: plotter.plot_histogram(temp_df['self_employed_weekly_hours'], title=\"Self Employed Weekly Hours Worked\", log_scale=False, rotation=0)\n",
    "\n",
    "new_df['self_employed_weekly_hours'] = temp_df['self_employed_weekly_hours'] \n",
    "\n",
    "'''\n",
    "CASUAL_WORK : Integer (Class)\n",
    "\n",
    "1 or 0 if participant is does casual work, eg. Farming, Vendoring. Missing replaced with Refused since both indicate similar decisions\n",
    "'''\n",
    "df['casual_work'] = df['casual_work'].replace('Missing', 'Refused')\n",
    "temp_df['casual_work'], getCasualWorkBool = pd.factorize(df['casual_work'])\n",
    "print(\"CASUAL_WORK:\", getCasualWorkBool,\"\\n\", temp_df['casual_work'].unique())\n",
    "\n",
    "if PLOT: plotter.plot_bar(df['casual_work'], title=\"Casual Work\", log_scale=False, rotation=0)\n",
    "\n",
    "new_df['casual_work'] = temp_df['casual_work']\n",
    "\n",
    "'''\n",
    "CASUAL_WEEKLY_HOURS : Integer\n",
    "\n",
    "Replaced any item that was a string or NA with 0. I haven't binned this feature since Hours worked weekly will have frequent hour amounts.\n",
    "'''\n",
    "df['casual_weekly_hours'] = df['casual_weekly_hours'].replace('Missing', 0).replace(\"Refused\", 0).replace(\"Don't know\", 0).replace(pd.NA, 0).replace(\"Not Applicable\", 0)\n",
    "df['casual_weekly_hours'] =  pd.to_numeric(df['casual_weekly_hours']).astype('Int32')\n",
    "\n",
    "# CAPPED ENTRIES WHERE EMPLOYED WEEKLY HOURS IS GREATER THAN 100\n",
    "# IF A PARTICIPANT HAS MORE THAN 100 HOURS WORKED, THIS GETS CLIPPED DOWN TO 100\n",
    "temp_df['casual_weekly_hours'] = df['casual_weekly_hours'].clip(upper=100)\n",
    "\n",
    "if PLOT: plotter.plot_histogram(temp_df['casual_weekly_hours'], title=\"Weekly Hours Worked for Casual Work\", log_scale=False, rotation=0)\n",
    "\n",
    "new_df['casual_weekly_hours'] = temp_df['casual_weekly_hours'] \n",
    "\n",
    "'''\n",
    "EXTRA_INCOME (Derived) : Float\n",
    "\n",
    "There are a list of columns relating to extra incomes received from various sources. These include government grants, gifts, dontations etc.\n",
    "\n",
    "Each column will be summed to form a new column that represents the total income gained from extra sources, other than employment.\n",
    "'''\n",
    "# # Firstly replacing entries which aren't numbers with 0\n",
    "# for income_type in other_incomes:\n",
    "#     df[income_type] = df[income_type].replace('Missing', 0.0).replace(\"Refused\", 0.0).replace(\"Don't know\", 0.0).replace(pd.NA, 0.0).replace(\"Not Applicable\", 0.0)\n",
    "#     df[income_type] = pd.to_numeric(df[income_type])\n",
    "#     print(df[income_type].unique())\n",
    "\n",
    "# temp_df['extra_income'] = df[other_incomes[0]]\n",
    "# for i in range(1, len(other_incomes)):\n",
    "#     temp_df['extra_income'] += df[other_incomes[i]]\n",
    "\n",
    "# if PLOT: plotter.plot_histogram(temp_df['extra_income'], title=\"Extra income gained from sources other than employment\", log_scale=True, rotation=90)\n",
    "\n",
    "# new_df['extra_income'] = pd.factorize(pd.cut(pd.to_numeric(temp_df['extra_income']), bins=30))\n",
    "\n",
    "# print(temp_df['extra_income'].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4294c9f9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Section G: Personal ownership and debt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525b6a79",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Section H: Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43873b26",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "HIGHEST_GRADE_SCHOOL : Integer (Class)\n",
    "\n",
    "Includes missing, refused, not applicable and don't know as options/values.\n",
    "'''\n",
    "temp_df['highest_grade_school'], getHighestGradeSchool = pd.factorize(df['highest_grade_school'])\n",
    "print(\"HIGHEST_GRADE_SCHOOL:\", getHighestGradeSchool,\"\\n\", temp_df['highest_grade_school'].unique())\n",
    "\n",
    "if PLOT: plotter.plot_bar(df['highest_grade_school'], title=\"Highest grade completed of Schooling\", log_scale=False, rotation=90)\n",
    "\n",
    "new_df['highest_grade_school'] = temp_df['highest_grade_school']\n",
    "\n",
    "'''\n",
    "TERTIARY_EDUCATION : Integer (Class)\n",
    "\n",
    "Whether the participant completed some form of Tertiary Education (Degrees, Certificates etc.)\n",
    "\n",
    "Includes missing, refused, and don't know as options/values.\n",
    "'''\n",
    "temp_df['tertiary_education'], getTertiaryEducation = pd.factorize(df['tertiary_education'].replace(pd.NA, 'Missing'))\n",
    "print(\"TERTIARY_EDUCATION:\", getTertiaryEducation,\"\\n\", temp_df['tertiary_education'].unique())\n",
    "\n",
    "if PLOT: plotter.plot_bar(df['tertiary_education'], title=\"Attended Tertiary Schooling (Degrees, Certificates etc.)\", log_scale=False, rotation=0)\n",
    "\n",
    "new_df['tertiary_education'] = temp_df['tertiary_education']\n",
    "\n",
    "'''\n",
    "CURRENTLY_ENROLLED : Integer (Class)\n",
    "\n",
    "Whether the participant is enrolled in some form of Schooling or Education this year.\n",
    "\n",
    "Includes missing as an option/value.\n",
    "'''\n",
    "temp_df['currently_enrolled'], getCurrentlyEnrolled = pd.factorize(df['currently_enrolled'].replace(pd.NA, 'Missing'))\n",
    "print(\"CURRENTLY_ENROLLED:\", getCurrentlyEnrolled,\"\\n\", temp_df['currently_enrolled'].unique())\n",
    "\n",
    "if PLOT: plotter.plot_bar(df['currently_enrolled'], title=\"Currently Enrolled\", log_scale=False, rotation=0)\n",
    "\n",
    "new_df['currently_enrolled'] = temp_df['currently_enrolled']\n",
    "\n",
    "# '''\n",
    "# ATTENDED_COURSES : Integer (Class)\n",
    "\n",
    "# Whether the participant attended university/school courses in the prior year.\n",
    "\n",
    "# Includes missing, refused, and don't know as options/values.\n",
    "# '''\n",
    "# temp_df['attended_courses'], getAttendedCourses = pd.factorize(df['attended_courses'].replace(pd.NA, 'Missing'))\n",
    "# print(\"ATTENDED_COURSES:\", getAttendedCourses,\"\\n\", temp_df['attended_courses'].unique())\n",
    "\n",
    "# if PLOT: plotter.plot_bar(df['attended_courses'], title=\"Attended Courses Last Year (Degrees, Certificates etc.)\", log_scale=False, rotation=0)\n",
    "\n",
    "# new_df['attended_courses'] = temp_df['attended_courses']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd9798b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Section J: Health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135aa20e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "HEALTH_STATUS : Integer (Class)\n",
    "\n",
    "Ranges from 1-5. Self-description of current health, 1 being excellent, 5 being poor\n",
    "\n",
    "Decided to include missing, don't know and refused as options since they might reveal correlations.\n",
    "'''\n",
    "temp_df['health_status'], getHealthStatus = pd.factorize(df['health_status'])\n",
    "print(\"HEALTH_STATUS:\", getHealthStatus,\"\\n\", temp_df['health_status'].unique())\n",
    "\n",
    "if PLOT: plotter.plot_bar(df['health_status'], title=\"Health status\", log_scale=False, rotation=30)\n",
    "\n",
    "'''\n",
    "The following section is a list of health condition features. The participant was asked to say yes to any of the following conditions if they experienced them in the past 30 days.\n",
    "'''\n",
    "\n",
    "conditions = [\n",
    "    \"flu_symptoms\",\n",
    "    \"fever\",\n",
    "    \"persistent_cough\",\n",
    "    \"cough_with_blood\",\n",
    "    \"tight_chest\",\n",
    "    \"chest_pain\",\n",
    "    \"body_ache\",\n",
    "    \"headache\",\n",
    "    \"back_ache\",\n",
    "    \"joint_pain_arthritis\",\n",
    "    \"vomiting\",\n",
    "    \"diarrhoea\",\n",
    "    \"felt_weak\",\n",
    "    \"pain_in_upper_abdomen\",\n",
    "    \"pain_in_lower_abdomen\",\n",
    "    \"painful_urination\",\n",
    "    \"swelling_ankles\",\n",
    "    \"rash\",\n",
    "    \"skin_disorders\",\n",
    "    \"conjunctivitis_eye_infection\",\n",
    "    \"severe_weight_loss\",\n",
    "    \"yellow_eyes\",\n",
    "    \"memory_loss\",\n",
    "    \"serious_injury\"\n",
    "]\n",
    "\n",
    "getConditions = []\n",
    "\n",
    "for condition in conditions:\n",
    "    new_df[condition], getCondition = pd.factorize(df[condition].replace('Not Applicable', 'Missing'))\n",
    "    getConditions.append(getCondition)\n",
    "\n",
    "# Generate summary statistics for all condition columns\n",
    "summary_stats = new_df[conditions].describe()\n",
    "\n",
    "# Print the summary stats\n",
    "print(\"SUMMARY STATISTICS FOR VARIOUS HEALTH CONDITIONS\\n\", summary_stats)\n",
    "\n",
    "'''\n",
    "TIME_SINCE_PREV_CONSULTATION : Integer (Class)\n",
    "\n",
    "Options range from 1 (In the last 30 days) to 8 (Never)\n",
    "'''\n",
    "if wave_num == 2: df['time_since_prev_consulation'] = df['time_since_prev_consulation'].replace(\"Not asked in Phase 2\", \"Don't know\")\n",
    "\n",
    "temp_df['time_since_prev_consulation'], getTimeSincePrevConsulation = pd.factorize(df['time_since_prev_consulation'].replace(\"Not asked in Phase 2\", \"Don't know\"))\n",
    "print(\"TIME_SINCE_PREV_CONSULTATION:\", getTimeSincePrevConsulation,\"\\n\", temp_df['time_since_prev_consulation'].unique())\n",
    "\n",
    "if PLOT: plotter.plot_bar(df['time_since_prev_consulation'], title=\"Last health consultation\", log_scale=False, rotation=90)\n",
    "\n",
    "new_df['time_since_prev_consulation'] = temp_df['time_since_prev_consulation']\n",
    "\n",
    "'''\n",
    "MEDICINE_PRESCRIBED_AT_PREV_CONSULTATION: Integer (Class)\n",
    "\n",
    "If this feature is Nan, it indicates that the participants previous consultation was more than one and less two years ago, according to the questionnaire.\n",
    "Thus I created a new value \"Consultation Too Distant\" for these entries.\n",
    "'''\n",
    "df['medicine_prescribed_at_prev_consulation'] = df['medicine_prescribed_at_prev_consulation'].replace(pd.NA, \"Consultation Too Distant\")\n",
    "temp_df['medicine_prescribed_at_prev_consulation'], getMedicinePrescribedAtPrevConsulation = pd.factorize(df['medicine_prescribed_at_prev_consulation'])\n",
    "print(\"MEDICINE_PRESCRIBED_AT_PREV_CONSULTATION:\", getMedicinePrescribedAtPrevConsulation,\"\\n\", temp_df['medicine_prescribed_at_prev_consulation'].unique())\n",
    "\n",
    "if PLOT: plotter.plot_bar(df['medicine_prescribed_at_prev_consulation'], title=\"Medicine prescribed at last health consultation\", log_scale=False, rotation=70)\n",
    "\n",
    "new_df['medicine_prescribed_at_prev_consulation'] = temp_df['medicine_prescribed_at_prev_consulation']\n",
    "\n",
    "\n",
    "'''\n",
    "The following section is a list of persistent/long-term health conditions.\n",
    "\n",
    "Each condition is a separate feature, with an associated feature for the number of years since the diagnosis (at the time of the interview).\n",
    "'''\n",
    "\n",
    "temp_df['had_tubercolosis'], getHadTB = pd.factorize(df['had_tubercolosis'].replace({'No': 0, \"Yes\": 1}))\n",
    "temp_df['had_high_blood_pressure'], getHadTB = pd.factorize(df['had_high_blood_pressure'].replace({'No': 0, \"Yes\": 1}))\n",
    "temp_df['had_diabetes_or_high_blood_sugar'], getHadTB = pd.factorize(df['had_diabetes_or_high_blood_sugar'].replace({'No': 0, \"Yes\": 1}))\n",
    "temp_df['had_stroke'], getHadTB = pd.factorize(df['had_stroke'].replace({'No': 0, \"Yes\": 1}))\n",
    "temp_df['had_asthma'], getHadTB = pd.factorize(df['had_asthma'].replace({'No': 0, \"Yes\": 1}))\n",
    "temp_df['had_heart_problems'], getHadTB = pd.factorize(df['had_heart_problems'].replace({'No': 0, \"Yes\": 1}))\n",
    "temp_df['had_cancer'], getHadTB = pd.factorize(df['had_cancer'].replace({'No': 0, \"Yes\": 1}))\n",
    "\n",
    "persistent_conditions = ['tb', 'hbp', 'dia', 'strk', 'ast', 'hrt', 'can']\n",
    "mapping = {'tb': 'tubercolosis', 'hbp': 'high_blood_pressure', 'dia': 'diabetes_or_high_blood_sugar', 'strk': 'stroke', 'ast': 'asthma', 'hrt': 'heart_problems', 'can': 'cancer'}\n",
    "\n",
    "for con in persistent_conditions:\n",
    "    # Replace invalid entries in tb_diagnosis_year with -200 as a flag\n",
    "    years = df[f'{con}_diagnosis_year'].replace(['Missing', \"Don't know\", 'Refused', pd.NA], -200).dropna().astype(float)\n",
    "\n",
    "    # Calculate diagnosis age for those who had tuberculosis\n",
    "    temp_df[f'{con}_diagnosis_age'] = df[f'w{wave_num}_a_intrv_y'] - years\n",
    "\n",
    "    # Identify entries where the above flag is true\n",
    "    temp_df[f'w{wave_num}_a_intrv_y'] = df[f'w{wave_num}_a_intrv_y']\n",
    "    condition = (temp_df[f'{con}_diagnosis_age'] == temp_df[f'w{wave_num}_a_intrv_y'] + 200)\n",
    "\n",
    "    # Set those diagnosis age entries to -1\n",
    "    temp_df.loc[condition, f'{con}_diagnosis_age'] = -1\n",
    "\n",
    "    mapped_condition = mapping[con]\n",
    "    # Set diagnosis age to -1 if 'had_tuberculosis' is not 1\n",
    "    temp_df[f'{con}_diagnosis_age'] = temp_df[f'{con}_diagnosis_age'].where(df[f'had_{mapped_condition}'] != 1, -1)\n",
    "\n",
    "    # Convert to Int32 (to allow for -1 and NaN values)\n",
    "    new_df[f'{con}_diagnosis_age'] = temp_df[f'{con}_diagnosis_age'].astype('Int32')\n",
    "\n",
    "    print(new_df[f'{con}_diagnosis_age'].unique(), new_df[f'{con}_diagnosis_age'].count())\n",
    "\n",
    "'''\n",
    "EXERCISE_FREQUENCY : Integer (Class)\n",
    "\n",
    "Options are:\n",
    "Never\n",
    "Less than once a week\n",
    "Once a week\n",
    "Twice a week\n",
    "Three or more times a week\n",
    "'''\n",
    "if wave_num == 2: df['exercise_frequency'] = df['exercise_frequency'].replace(\"Not asked in Phase 2\", \"Don't know\")\n",
    "\n",
    "temp_df['exercise_frequency'], getExerciseFrequency = pd.factorize(df['exercise_frequency'].replace(\"Not asked in Phase 2\", \"Don't know\"))\n",
    "print(\"EXERCISE_FREQUENCY:\", getExerciseFrequency,\"\\n\", temp_df['exercise_frequency'].unique())\n",
    "\n",
    "if PLOT: plotter.plot_bar(df['exercise_frequency'], title=\"Frequency of Exercise\", log_scale=False, rotation=70)\n",
    "\n",
    "new_df['exercise_frequency'] = temp_df['exercise_frequency']\n",
    "\n",
    "'''\n",
    "SMOKES_CIGARETTES : Integer (Class)\n",
    "\n",
    "Yes or no.\n",
    "'''\n",
    "if wave_num == 2: df['smokes_cigarettes'] = df['smokes_cigarettes'].replace(\"Not asked in Phase 2\", \"Don't know\")\n",
    "\n",
    "df['smokes_cigarettes'] = df['smokes_cigarettes'].replace({pd.NA: 'Missing', 'Not Applicable': 'Missing'}).replace(\"Not asked in Phase 2\", \"Don't know\")\n",
    "temp_df['smokes_cigarettes'], getSmoker = pd.factorize(df['smokes_cigarettes'])\n",
    "print(\"SMOKES_CIGARETTES:\", getSmoker,\"\\n\", temp_df['smokes_cigarettes'].unique())\n",
    "\n",
    "if PLOT: plotter.plot_bar(df['smokes_cigarettes'], title=\"Whether participant smokes\", log_scale=False, rotation=0)\n",
    "\n",
    "new_df['smokes_cigarettes'] = temp_df['smokes_cigarettes']\n",
    "\n",
    "'''\n",
    "ALCOHOL_FREQUENCY : Integer (Class)\n",
    "\n",
    "Options are:\n",
    "I have never drunk alcohol→ SKIP TO J33 1\n",
    "I no longer drink alcohol→ SKIP TO J33 2\n",
    "I drink very rarely 3\n",
    "Less than once a week 4\n",
    "On 1 or 2 days a week 5\n",
    "On 3 or 4 days a week 6\n",
    "On 5 or 6 days a week 7\n",
    "Every day 8\n",
    "'''\n",
    "if wave_num == 2: df['alcohol_frequency'] = df['alcohol_frequency'].replace(\"Not asked in Phase 2\", \"Don't know\")\n",
    "\n",
    "temp_df['alcohol_frequency'], getAlcoholFrequency = pd.factorize(df['alcohol_frequency'].replace(\"Not asked in Phase 2\", \"Don't know\"))\n",
    "print(\"ALCOHOL_FREQUENCY:\", getAlcoholFrequency,\"\\n\", temp_df['alcohol_frequency'].unique())\n",
    "\n",
    "if PLOT: plotter.plot_bar(df['alcohol_frequency'], title=\"Frequency of alcohol drinking\", log_scale=False, rotation=70)\n",
    "\n",
    "new_df['alcohol_frequency'] = temp_df['alcohol_frequency']\n",
    "\n",
    "'''\n",
    "ALCOHOL_QUANTITY : Integer (Class)\n",
    "\n",
    "Options are:\n",
    "13 or more standard drinks 1\n",
    "9 to 12 standard drinks 2\n",
    "7 to 8 standard drinks 3\n",
    "5 to 6 standard drinks 4\n",
    "3 or 4 standard drinks 5\n",
    "1 or 2 standard drinks 6\n",
    "'''\n",
    "if wave_num == 2: df['alcohol_quantity'] = df['alcohol_quantity'].replace(\"Not asked in Phase 2\", \"Don't know\")\n",
    "\n",
    "temp_df['alcohol_quantity'], getAlcoholQuantity = pd.factorize(df['alcohol_quantity'])\n",
    "print(\"ALCOHOL_QUANTITY:\", getAlcoholQuantity,\"\\n\", temp_df['alcohol_quantity'].unique())\n",
    "\n",
    "if PLOT: plotter.plot_bar(df['alcohol_quantity'], title=\"Quantity of alcohol drinking\", log_scale=False, rotation=70)\n",
    "\n",
    "new_df['alcohol_quantity'] = temp_df['alcohol_quantity']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c66bd4e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Section N: Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1609b50",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# f'w{wave_num}_a_height_1'\n",
    "# f'w{wave_num}_a_weight_1'\n",
    "# f'w{wave_num}_a_waist_1'\n",
    "\n",
    "'''\n",
    "The following columns all relate to measurements done during the interview of each participant.\n",
    "\n",
    "These include: Height, Weight, Waist\n",
    "\n",
    "Each column is cut/binned to create new discrete columns.\n",
    "'''\n",
    "\n",
    "# Replace NaN values with the mean of the column\n",
    "\n",
    "# print(df['height_measurement'].replace({'Missing': pd.NA, 'Refused': pd.NA, 'Not Applicable': pd.NA, \"Don't know\": pd.NA}).dropna().count())\n",
    "# height_ave = df['height_measurement'].replace({'Missing': pd.NA, 'Refused': pd.NA, 'Not Applicable': pd.NA, \"Don't know\": pd.NA}).dropna().astype(float).mean()\n",
    "# weight_ave = df['weight_measurement'].replace({'Missing': pd.NA, 'Refused': pd.NA, 'Not Applicable': pd.NA, \"Don't know\": pd.NA}).dropna().astype(float).mean()\n",
    "# waist_ave = df['waist_measurement'].replace({'Missing': pd.NA, 'Refused': pd.NA, 'Not Applicable': pd.NA, \"Don't know\": pd.NA}).dropna().astype(float).mean()\n",
    "\n",
    "if wave_num == 2:\n",
    "    df['height_measurement'] = df['height_measurement'].replace('Not asked in Phase 2', pd.NA)\n",
    "    df['weight_measurement'] = df['weight_measurement'].replace('Not asked in Phase 2', pd.NA)\n",
    "    df['waist_measurement'] = df['waist_measurement'].replace('Not asked in Phase 2', pd.NA)\n",
    "\n",
    "height_diff = df['height_measurement'].count()\n",
    "weight_diff = df['weight_measurement'].count()\n",
    "waist_diff = df['waist_measurement'].count()\n",
    "\n",
    "temp_df['height_measurement'] = df['height_measurement'].replace({'Missing': pd.NA, 'Refused': pd.NA, 'Not Applicable': pd.NA, \"Don't know\": pd.NA}).dropna().astype(float)\n",
    "temp_df['weight_measurement'] = df['weight_measurement'].replace({'Missing': pd.NA, 'Refused': pd.NA, 'Not Applicable': pd.NA, \"Don't know\": pd.NA}).dropna().astype(float)\n",
    "temp_df['waist_measurement'] = df['waist_measurement'].replace({'Missing': pd.NA, 'Refused': pd.NA, 'Not Applicable': pd.NA, \"Don't know\": pd.NA}).dropna().astype(float)\n",
    "\n",
    "if PLOT: plotter.plot_histogram(temp_df['height_measurement'], \"Distribution of Heights\")\n",
    "if PLOT: plotter.plot_histogram(temp_df['weight_measurement'], \"Distribution of Weights\")\n",
    "if PLOT: plotter.plot_histogram(temp_df['waist_measurement'], \"Distribution of Waist Measurements\")\n",
    "\n",
    "new_df['height_measurement'] = pd.cut(temp_df['height_measurement'], bins=100).astype('category').cat.codes\n",
    "new_df['weight_measurement'] = pd.cut(temp_df['weight_measurement'], bins=100).astype('category').cat.codes\n",
    "new_df['waist_measurement'] = pd.cut(temp_df['waist_measurement'], bins=100).astype('category').cat.codes\n",
    "\n",
    "height_diff -= new_df['height_measurement'].count()\n",
    "weight_diff -= new_df['weight_measurement'].count()\n",
    "waist_diff -=  new_df['waist_measurement'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a8a183",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58a991b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Sampling for dropped values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea06093",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Count before dropping NA:\\n\", df['pid'].count())\n",
    "\n",
    "new_df = new_df.dropna()\n",
    "\n",
    "print(\"Count after dropping NA:\\n\", new_df['pid'].count())\n",
    "\n",
    "diff = df['pid'].count() - new_df['pid'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0518dbae",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Exporting Dataframes to CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f727c10",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col in cesd_col_names:    \n",
    "    # Header text for each column based on wave\n",
    "    header = 'w' + str(wave_num)\n",
    "\n",
    "    new_df[header+col] = df[header+col]\n",
    "\n",
    "new_df.to_csv(f'CSV/wave{wave_num}_select.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31690582",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Labelling\n",
    "\n",
    "Each participant was **labelled according to the CESD-10 reporting scale**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfbdc6b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from tqdm import tqdm\n",
    "# from typing import List\n",
    "# importlib.reload(plotter)\n",
    "\n",
    "# import warnings\n",
    "\n",
    "# warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# class Wave:\n",
    "#     def __init__(self, data: pd.DataFrame, select_cols: List[str]):\n",
    "#         self.data: pd.DataFrame = data\n",
    "#         self.select_cols: List[str] = select_cols\n",
    "    \n",
    "#     def __str__(self):\n",
    "#         return str(self.data)\n",
    "\n",
    "# waves: List[Wave] = []\n",
    "\n",
    "# # Scoring dictionaries\n",
    "# normal_scoring = {\n",
    "#     'Rarely or none of the time (less than 1 day)': 0,\n",
    "#     'Some or little of the time (1-2 days)': 1,\n",
    "#     'Occasionally or a moderate amount of time (3-4 days)': 2,\n",
    "#     'All of the time (5-7 days)': 3\n",
    "# }\n",
    "\n",
    "# reverse_scoring = {\n",
    "#     'Rarely or none of the time (less than 1 day)': 3,\n",
    "#     'Some or little of the time (1-2 days)': 2,\n",
    "#     'Occasionally or a moderate amount of time (3-4 days)': 1,\n",
    "#     'All of the time (5-7 days)': 0\n",
    "# }\n",
    "\n",
    "# incidence = []\n",
    "\n",
    "# # Loop through each wave\n",
    "# for i in tqdm(range(1, 3), desc=\"Labelling Participants\"):\n",
    "#     url = 'CSV/wave' + str(i) + '_select.csv'\n",
    "#     data = pd.read_csv(url)\n",
    "\n",
    "#     # Header text for each column based on wave\n",
    "#     header = 'w' + str(i)\n",
    "    \n",
    "#     # Create the select columns\n",
    "#     select_cols = [header + col for col in cesd_col_names]\n",
    "\n",
    "#     # Filter rows based on valid CESD answers\n",
    "#     cesd_valid_answers = ['Rarely or none of the time (less than 1 day)',\n",
    "#                           'Some or little of the time (1-2 days)',\n",
    "#                           'Occasionally or a moderate amount of time (3-4 days)',\n",
    "#                           'All of the time (5-7 days)']\n",
    "    \n",
    "#     # Only keep rows where all select_cols have valid answers\n",
    "#     # new_data = data[data[select_cols].isin(cesd_valid_answers).all(axis=1)].fillna(data.mode(), inplace=True)\n",
    "#     new_data = data[data[select_cols].isin(cesd_valid_answers).all(axis=1)]\n",
    "    \n",
    "#     # Apply scoring to all CESD columns\n",
    "#     for idx, col in enumerate(select_cols):\n",
    "#         if idx == 4 or idx == 7:  # Reverse scoring for columns 5 and 8 (0-indexed as 4 and 7)\n",
    "#             new_data[col] = new_data[col].replace(reverse_scoring)\n",
    "#         else:\n",
    "#             new_data[col] = new_data[col].replace(normal_scoring)\n",
    "\n",
    "#     # Derive \"Depressed\" column: 1 if score >= 10, else 0\n",
    "#     new_data['score'] = new_data[select_cols].sum(axis=1)\n",
    "#     new_data['depressed'] = (new_data['score'] >= 10).astype(int)\n",
    "\n",
    "#     # Check which rows have NaN values\n",
    "#     nan_rows = new_data[new_data.isna().any(axis=1)]\n",
    "\n",
    "#     # Print rows with NaN values\n",
    "#     print(nan_rows)\n",
    "\n",
    "#     new_data.to_csv(f'CSV/wave{wave_num}_select_labelled.csv', index=False)\n",
    "\n",
    "#     percentage_depressed = if PLOT: plotter.get_percent_na(new_data['depressed'].replace(1, pd.NA))\n",
    "\n",
    "#     incidence.append(percentage_depressed)\n",
    "\n",
    "#     # Append the wave object to the list\n",
    "#     wave = Wave(new_data, select_cols)\n",
    "#     waves.append(wave)\n",
    "\n",
    "# for i in range(len(incidence)): print((f\"Wave {i+1}: {round(incidence[i], 3)}% depressed\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2321f560",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3842f005",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# import pandas as pd\n",
    "# from typing import List, Dict, Tuple\n",
    "# import warnings\n",
    "\n",
    "# warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# # Selecting column names for CESD-10 Scale related features\n",
    "# cesd_col_names = [\"_a_emobth\", \"_a_emomnd\", \"_a_emodep\", \"_a_emoeff\", \"_a_emohope\",\n",
    "#                 \"_a_emofear\", \"_a_emoslp\", \"_a_emohap\", \"_a_emolone\", \"_a_emogo\"]\n",
    "\n",
    "# for wave in range(len(waves)):\n",
    "#     print(f\"Wave {wave+1}:\")\n",
    "#     data: pd.DataFrame = waves[wave].data\n",
    "#     select_cols = waves[wave].get_select_cols()\n",
    "\n",
    "#     # Dictionary to store the scores and depression status\n",
    "#     scores: Dict[str, Dict] = dict()\n",
    "\n",
    "#     # Series containing participant IDs\n",
    "#     participants = data['pid']\n",
    "\n",
    "#     # Counter for the number of participants flagged as depressed\n",
    "#     count_depressed = 0\n",
    "\n",
    "#     # Iterate over each participant\n",
    "#     for participant in tqdm(participants, desc=\"Labelling Participants\"):\n",
    "#         score = 0\n",
    "#         depressed = False\n",
    "\n",
    "#         idx = data.index[data['pid'] == participant]\n",
    "\n",
    "#         # Sum the scores for all relevant columns\n",
    "#         for col in select_cols:\n",
    "#             value = data.at[idx[0], col]  # Accessing the value using participant ID and column name\n",
    "#             score += value\n",
    "\n",
    "#         # Determine if the participant is depressed based on the score\n",
    "#         if score >= 10:\n",
    "#             depressed = True\n",
    "#             count_depressed += 1\n",
    "\n",
    "#         # Map the participant ID to their score and depression status\n",
    "#         scores[participant] = {'score': int(score), 'Depressed': depressed}\n",
    "    \n",
    "#     data['depression_score'] = 0\n",
    "\n",
    "#     for i in cesd_col_names:\n",
    "#         data['depression_score'] += data[f\"w{wave+1}{i}\"]\n",
    "    \n",
    "#     # Create a new column 'new_column' based on a condition\n",
    "#     data['depressed'] = data['depression_score'].apply(lambda x: 1 if x >= 10 else 0)\n",
    "\n",
    "#     print(list(data['depressed']).count(1))\n",
    "\n",
    "#     data.to_csv('wave1_select_labelled.csv')\n",
    "#     # Print the total number of depressed participants\n",
    "#     print(f\"Total Depressed Participants: {count_depressed}\")\n",
    "#     print(f\"Calculated Prevalence for Depression: {round(count_depressed/len(participants) * 100, 2)}%\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8.61315,
   "end_time": "2024-10-02T16:46:23.122708",
   "environment_variables": {},
   "exception": true,
   "input_path": "PreProcessing.ipynb",
   "output_path": "waveNotebooks/output_notebook.ipynb",
   "parameters": {
    "param_name": 3
   },
   "start_time": "2024-10-02T16:46:14.509558",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}