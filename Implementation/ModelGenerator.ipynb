{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/useradd/.local/lib/python3.10/site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy in /home/useradd/.local/lib/python3.10/site-packages (1.23.5)\n",
      "Requirement already satisfied: scikit-learn in /home/useradd/.local/lib/python3.10/site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: tensorflow in /home/useradd/.local/lib/python3.10/site-packages (2.12.0)\n",
      "Requirement already satisfied: tqdm in /home/useradd/.local/lib/python3.10/site-packages (4.66.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/useradd/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/useradd/.local/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/useradd/.local/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/useradd/.local/lib/python3.10/site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/useradd/.local/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/useradd/.local/lib/python3.10/site-packages (from scikit-learn) (3.3.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/useradd/.local/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/useradd/.local/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/useradd/.local/lib/python3.10/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/useradd/.local/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/useradd/.local/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/useradd/.local/lib/python3.10/site-packages (from tensorflow) (1.66.2)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/useradd/.local/lib/python3.10/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: jax>=0.3.15 in /home/useradd/.local/lib/python3.10/site-packages (from tensorflow) (0.4.30)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in /home/useradd/.local/lib/python3.10/site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/useradd/.local/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/useradd/.local/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/useradd/.local/lib/python3.10/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/useradd/.local/lib/python3.10/site-packages (from tensorflow) (4.25.5)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (59.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in /home/useradd/.local/lib/python3.10/site-packages (from tensorflow) (2.12.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /home/useradd/.local/lib/python3.10/site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/useradd/.local/lib/python3.10/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/useradd/.local/lib/python3.10/site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /home/useradd/.local/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/useradd/.local/lib/python3.10/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: jaxlib<=0.4.30,>=0.4.27 in /home/useradd/.local/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow) (0.4.30)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in /home/useradd/.local/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/useradd/.local/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.35.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/useradd/.local/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/useradd/.local/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/useradd/.local/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/useradd/.local/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/useradd/.local/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/useradd/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/useradd/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/useradd/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/useradd/.local/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/useradd/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/useradd/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/useradd/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/useradd/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/useradd/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /home/useradd/.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy scikit-learn tensorflow tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current models being implemented are namely:\n",
    "\n",
    "* Supervised\n",
    "    1. Logistic Regression Model\n",
    "    2. Random Forest Classifier\n",
    "    3. Support Vector Machine\n",
    "    4. Deep Neural Network\n",
    "    5. (New) Bayesian Network\n",
    "    6. (New) Gradient Boosting\n",
    "\n",
    "* Unsupervised\n",
    "    1. (New) K-Means Clustering\n",
    "    2. (New) Kernel Density Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import pandas as pd\n",
    "\n",
    "# Selecting column names for CESD-10 Scale related features\n",
    "cesd_col_names = [\"_a_emobth\", \"_a_emomnd\", \"_a_emodep\", \"_a_emoeff\", \"_a_emohope\",\n",
    "                \"_a_emofear\", \"_a_emoslp\", \"_a_emohap\", \"_a_emolone\", \"_a_emogo\"]\n",
    "\n",
    "cesd_col_names_w1 = [\"w1\" + col for col in cesd_col_names]\n",
    "cesd_col_names_w2 = [\"w2\" + col for col in cesd_col_names]\n",
    "cesd_col_names_w3 = [\"w3\" + col for col in cesd_col_names]\n",
    "cesd_col_names_w4 = [\"w4\" + col for col in cesd_col_names]\n",
    "cesd_col_names_w5 = [\"w5\" + col for col in cesd_col_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepping dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14156\n",
      "14589\n",
      "14746\n",
      "19294\n",
      "18779\n",
      "81564\n",
      "Index(['pid', 'age', 'gender', 'race', 'marital_status', 'born_province',\n",
      "       'employed', 'employed_take_home', 'employed_weekly_hours',\n",
      "       'self_employed', 'self_employed_take_home',\n",
      "       'self_employed_weekly_hours', 'casual_work', 'casual_weekly_hours',\n",
      "       'highest_grade_school', 'tertiary_education', 'currently_enrolled',\n",
      "       'fever', 'persistent_cough', 'cough_with_blood', 'chest_pain',\n",
      "       'body_ache', 'headache', 'back_ache', 'joint_pain_arthritis',\n",
      "       'diarrhoea', 'painful_urination', 'swelling_ankles',\n",
      "       'severe_weight_loss', 'time_since_prev_consulation',\n",
      "       'exercise_frequency', 'smokes_cigarettes', 'height_measurement',\n",
      "       'weight_measurement', 'waist_measurement', 'depressed'],\n",
      "      dtype='object') \n",
      "36 columns\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"CSV/wave1_select_labelled.csv\")\n",
    "df1 = df1.drop(columns=cesd_col_names_w1).drop(columns=['score'])\n",
    "print(df1['pid'].count())\n",
    "\n",
    "df2 = pd.read_csv(\"CSV/wave2_select_labelled.csv\")\n",
    "df2 = df2.drop(columns=cesd_col_names_w2).drop(columns=['score'])\n",
    "print(df2['pid'].count())\n",
    "\n",
    "df3 = pd.read_csv(\"CSV/wave3_select_labelled.csv\")\n",
    "df3 = df3.drop(columns=cesd_col_names_w3).drop(columns=['score'])\n",
    "print(df3['pid'].count())\n",
    "\n",
    "df4 = pd.read_csv(\"CSV/wave4_select_labelled.csv\")\n",
    "df4 = df4.drop(columns=cesd_col_names_w4).drop(columns=['score'])\n",
    "print(df4['pid'].count())\n",
    "\n",
    "df5 = pd.read_csv(\"CSV/wave5_select_labelled.csv\")\n",
    "df5 = df5.drop(columns=cesd_col_names_w5).drop(columns=['score'])\n",
    "print(df5['pid'].count())\n",
    "\n",
    "combined_df = pd.concat([df1, df2, df3, df4, df5], axis=0, ignore_index=True)\n",
    "print(combined_df['pid'].count())\n",
    "print(combined_df.columns, f\"\\n{len(combined_df.columns) - 1} columns\")\n",
    "\n",
    "# print(combined_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision = TP / TP + FP (How often are positive predictions correct?)\n",
    "Recall = TP / TP + FN (Can an ML model find all instances of the positive class?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.74\n",
      "Validation Confusion Matrix:\n",
      "[[12099    40]\n",
      " [ 4139    35]]\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.85     12139\n",
      "           1       0.47      0.01      0.02      4174\n",
      "\n",
      "    accuracy                           0.74     16313\n",
      "   macro avg       0.61      0.50      0.43     16313\n",
      "weighted avg       0.67      0.74      0.64     16313\n",
      "\n",
      "Test Accuracy: 0.75\n",
      "Test Confusion Matrix:\n",
      "[[12210    26]\n",
      " [ 4023    54]]\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86     12236\n",
      "           1       0.68      0.01      0.03      4077\n",
      "\n",
      "    accuracy                           0.75     16313\n",
      "   macro avg       0.71      0.51      0.44     16313\n",
      "weighted avg       0.73      0.75      0.65     16313\n",
      "\n",
      "Best Parameters: {'logisticregression__C': 1, 'logisticregression__penalty': 'l1'}\n",
      "Best Score: 0.7479872468708126\n"
     ]
    }
   ],
   "source": [
    "import logisticRegression\n",
    "\n",
    "LR = logisticRegression.LogisticRegressionModel(combined_df, combined_df['depressed'])\n",
    "\n",
    "LR.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 06:40:13.587110: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-04 06:40:13.626423: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-04 06:40:13.627813: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-04 06:40:17.526025: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-10-04 06:40:22.949706: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-04 06:40:22.950392: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510/510 [==============================] - 1s 1ms/step\n",
      "Validation Accuracy: 0.74\n",
      "Validation Confusion Matrix:\n",
      "[[11621   518]\n",
      " [ 3793   381]]\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.96      0.84     12139\n",
      "           1       0.42      0.09      0.15      4174\n",
      "\n",
      "    accuracy                           0.74     16313\n",
      "   macro avg       0.59      0.52      0.50     16313\n",
      "weighted avg       0.67      0.74      0.67     16313\n",
      "\n",
      "510/510 [==============================] - 1s 1ms/step\n",
      "Test Accuracy: 0.74\n",
      "Test Confusion Matrix:\n",
      "[[11744   492]\n",
      " [ 3694   383]]\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.96      0.85     12236\n",
      "           1       0.44      0.09      0.15      4077\n",
      "\n",
      "    accuracy                           0.74     16313\n",
      "   macro avg       0.60      0.53      0.50     16313\n",
      "weighted avg       0.68      0.74      0.68     16313\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import neuralNetwork\n",
    "\n",
    "NN = neuralNetwork.DeepNeuralNetworkModel(combined_df, combined_df['depressed'])\n",
    "\n",
    "NN.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.74\n",
      "Validation Confusion Matrix:\n",
      "[[11959   180]\n",
      " [ 3992   182]]\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.99      0.85     12139\n",
      "           1       0.50      0.04      0.08      4174\n",
      "\n",
      "    accuracy                           0.74     16313\n",
      "   macro avg       0.63      0.51      0.47     16313\n",
      "weighted avg       0.69      0.74      0.65     16313\n",
      "\n",
      "Test Accuracy: 0.75\n",
      "Test Confusion Matrix:\n",
      "[[12072   164]\n",
      " [ 3889   188]]\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.99      0.86     12236\n",
      "           1       0.53      0.05      0.08      4077\n",
      "\n",
      "    accuracy                           0.75     16313\n",
      "   macro avg       0.65      0.52      0.47     16313\n",
      "weighted avg       0.70      0.75      0.66     16313\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 300}: 100%|██████████| 108/108 [1:14:20<00:00, 41.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Best Score: 0.7498262981063468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import randomForest\n",
    "importlib.reload(randomForest)\n",
    "\n",
    "RF = randomForest.RandomForestModel(combined_df, combined_df['depressed'])\n",
    "\n",
    "RF.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.75\n",
      "Validation Confusion Matrix:\n",
      "[[12102    37]\n",
      " [ 4107    67]]\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.85     12139\n",
      "           1       0.64      0.02      0.03      4174\n",
      "\n",
      "    accuracy                           0.75     16313\n",
      "   macro avg       0.70      0.51      0.44     16313\n",
      "weighted avg       0.72      0.75      0.64     16313\n",
      "\n",
      "Test Accuracy: 0.75\n",
      "Test Confusion Matrix:\n",
      "[[12186    50]\n",
      " [ 4027    50]]\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86     12236\n",
      "           1       0.50      0.01      0.02      4077\n",
      "\n",
      "    accuracy                           0.75     16313\n",
      "   macro avg       0.63      0.50      0.44     16313\n",
      "weighted avg       0.69      0.75      0.65     16313\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: {'C': 0.1, 'degree': 2, 'gamma': 0.1, 'kernel': 'linear'}:   6%|▌         | 8/144 [1:48:18<28:34:07, 756.23s/it]   "
     ]
    }
   ],
   "source": [
    "import supportVectorMachine\n",
    "\n",
    "SVM = supportVectorMachine.SVMModel(combined_df, combined_df['depressed'])\n",
    "\n",
    "SVM.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
